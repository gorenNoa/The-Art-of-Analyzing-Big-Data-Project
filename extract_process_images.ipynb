{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc525328bc454f88b323c440029de845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44227f922613438f9178f1de3a477e46",
              "IPY_MODEL_66c77e305d4d4337bb0da1dde98707ea",
              "IPY_MODEL_3a20b2d757d24e769ec361462ef40610"
            ],
            "layout": "IPY_MODEL_48a5553078854425bf9d04bca9f6f998"
          }
        },
        "44227f922613438f9178f1de3a477e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee276d94c4b04f2a80ffa40bef84ea5a",
            "placeholder": "​",
            "style": "IPY_MODEL_5c55ae1ae91340d28de2bd630915bd4c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "66c77e305d4d4337bb0da1dde98707ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c290584c1ce448cb452ed357506fd7d",
            "max": 288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1581be0b6e094a569da433015fa88380",
            "value": 288
          }
        },
        "3a20b2d757d24e769ec361462ef40610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7519d6fb81eb45869c0261d2f6536aac",
            "placeholder": "​",
            "style": "IPY_MODEL_bd986d451f17402da08435638dc27476",
            "value": " 288/288 [00:00&lt;00:00, 30.4kB/s]"
          }
        },
        "48a5553078854425bf9d04bca9f6f998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee276d94c4b04f2a80ffa40bef84ea5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c55ae1ae91340d28de2bd630915bd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c290584c1ce448cb452ed357506fd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1581be0b6e094a569da433015fa88380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7519d6fb81eb45869c0261d2f6536aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd986d451f17402da08435638dc27476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c00fae74a3784d6ca98794697edc9120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb0029c13fa42d2a7811a236a28680e",
              "IPY_MODEL_68fc8484db834e0bade5f53cca48bb54",
              "IPY_MODEL_b050162a801e4368a3612dede2126678"
            ],
            "layout": "IPY_MODEL_b9ac609d615e4bcbb1c2e1093c559dca"
          }
        },
        "5fb0029c13fa42d2a7811a236a28680e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f17143dc12c447fbf8bc837be34e60d",
            "placeholder": "​",
            "style": "IPY_MODEL_6990158e65fe402fbe4c7594974a5868",
            "value": "config.json: 100%"
          }
        },
        "68fc8484db834e0bade5f53cca48bb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf9e3269b9cf49e4a5bb1b5ca503da4c",
            "max": 565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_680de0b3d07c4619924df999eaa10196",
            "value": 565
          }
        },
        "b050162a801e4368a3612dede2126678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303231f7e56c4b3fbd4e732c73bc9d3e",
            "placeholder": "​",
            "style": "IPY_MODEL_5f272e7cdb6247caac8b7657fad05e6b",
            "value": " 565/565 [00:00&lt;00:00, 53.9kB/s]"
          }
        },
        "b9ac609d615e4bcbb1c2e1093c559dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f17143dc12c447fbf8bc837be34e60d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6990158e65fe402fbe4c7594974a5868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf9e3269b9cf49e4a5bb1b5ca503da4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680de0b3d07c4619924df999eaa10196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "303231f7e56c4b3fbd4e732c73bc9d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f272e7cdb6247caac8b7657fad05e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffa03d32760748a1b9a60fa5f826bcb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecf3c2a96bb9486b8497654fb02cb945",
              "IPY_MODEL_5e55572ec17e4c9aafcfcb4a37d05276",
              "IPY_MODEL_51e9c8e2a21a490aa3b4b82ddd666a6b"
            ],
            "layout": "IPY_MODEL_85f3134a50364645bb9e855a95793fa0"
          }
        },
        "ecf3c2a96bb9486b8497654fb02cb945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b4451033fd4d3191edd348e069d115",
            "placeholder": "​",
            "style": "IPY_MODEL_c8def8e6b82f4686aa8691280511cbcc",
            "value": "vocab.txt: "
          }
        },
        "5e55572ec17e4c9aafcfcb4a37d05276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85bba20409284ef2888b50c5687092bf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_875efd7ba144463ea9440762bfc52316",
            "value": 1
          }
        },
        "51e9c8e2a21a490aa3b4b82ddd666a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d9309d4b6024bcaab322da10589b9c9",
            "placeholder": "​",
            "style": "IPY_MODEL_603f71a4799b4417bbdd02940d05f4a7",
            "value": " 545k/? [00:00&lt;00:00, 20.8MB/s]"
          }
        },
        "85f3134a50364645bb9e855a95793fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b4451033fd4d3191edd348e069d115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8def8e6b82f4686aa8691280511cbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85bba20409284ef2888b50c5687092bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "875efd7ba144463ea9440762bfc52316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d9309d4b6024bcaab322da10589b9c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603f71a4799b4417bbdd02940d05f4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5329467d74fd4071a24b064492d17365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_842a77ba282d4ad8833aeb9ab3a10403",
              "IPY_MODEL_35f9e97618b14eca8433138cc0ba011d",
              "IPY_MODEL_2188fc1e91e2472f898c596ae79cd8e4"
            ],
            "layout": "IPY_MODEL_1de2848f29f84acbb464fcd3f80ad39c"
          }
        },
        "842a77ba282d4ad8833aeb9ab3a10403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_142415c5496c4567aeb982db7624e4b2",
            "placeholder": "​",
            "style": "IPY_MODEL_954275880c53458db0ade5f5733094d1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "35f9e97618b14eca8433138cc0ba011d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_042177b305914596b25bdf74819ccbdd",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d09e1c841fe4a0cb3b3644f4a5c52e1",
            "value": 112
          }
        },
        "2188fc1e91e2472f898c596ae79cd8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850646c348ff45fc9b8a186c2acc551e",
            "placeholder": "​",
            "style": "IPY_MODEL_77447efb4f0b4d53844c2e676817020f",
            "value": " 112/112 [00:00&lt;00:00, 9.69kB/s]"
          }
        },
        "1de2848f29f84acbb464fcd3f80ad39c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142415c5496c4567aeb982db7624e4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "954275880c53458db0ade5f5733094d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "042177b305914596b25bdf74819ccbdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d09e1c841fe4a0cb3b3644f4a5c52e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "850646c348ff45fc9b8a186c2acc551e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77447efb4f0b4d53844c2e676817020f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94cecb7a9f5044ce98dacd85a1507fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e6a95a09e234b1f87284dd1ca61e537",
              "IPY_MODEL_4f1888ab3f664c5a8d0582f022eaaeb6",
              "IPY_MODEL_33f2ae033d5a4c2e8c3de22b8ea6d42e"
            ],
            "layout": "IPY_MODEL_6e3e161e14f041b9913bb569252e34d8"
          }
        },
        "0e6a95a09e234b1f87284dd1ca61e537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8df6dd0457b44d0b82473804aa7ce319",
            "placeholder": "​",
            "style": "IPY_MODEL_35be83ffd1fc47feaac877c0ff6f800f",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4f1888ab3f664c5a8d0582f022eaaeb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a48a73f7269b4d268553565923aec3e3",
            "max": 504210578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_449b3dc89678433690daf76402558375",
            "value": 504210578
          }
        },
        "33f2ae033d5a4c2e8c3de22b8ea6d42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_697651a6bf17469985ce7baca6a527a6",
            "placeholder": "​",
            "style": "IPY_MODEL_19c90adc72454f00be4366bf613328f1",
            "value": " 504M/504M [00:06&lt;00:00, 81.7MB/s]"
          }
        },
        "6e3e161e14f041b9913bb569252e34d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df6dd0457b44d0b82473804aa7ce319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35be83ffd1fc47feaac877c0ff6f800f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a48a73f7269b4d268553565923aec3e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449b3dc89678433690daf76402558375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "697651a6bf17469985ce7baca6a527a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c90adc72454f00be4366bf613328f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27db0446f4dd475d8e619d62d8c94582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d29b352ebb5b42598f9d232f8459f0bc",
              "IPY_MODEL_eef6c57c37f647ff9df3a7970c224bfa",
              "IPY_MODEL_6de9e425ac6a4f5a96493f6b5b3b7432"
            ],
            "layout": "IPY_MODEL_43e6b0fb7d99467aab93361e18d7d463"
          }
        },
        "d29b352ebb5b42598f9d232f8459f0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b31d970f7d843fcb56cb957400f0ba0",
            "placeholder": "​",
            "style": "IPY_MODEL_853ce92128d34c91ba466cca5ae36c69",
            "value": "model.safetensors: 100%"
          }
        },
        "eef6c57c37f647ff9df3a7970c224bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66ce15787414c95abae030df395cc98",
            "max": 504148352,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ab7633239e646c5bafdc7c1655729f7",
            "value": 504148352
          }
        },
        "6de9e425ac6a4f5a96493f6b5b3b7432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f514fb6d943c4b7683106346c8b4688f",
            "placeholder": "​",
            "style": "IPY_MODEL_e715a340fa9f46b6832ffb657025451c",
            "value": " 504M/504M [00:09&lt;00:00, 103MB/s]"
          }
        },
        "43e6b0fb7d99467aab93361e18d7d463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b31d970f7d843fcb56cb957400f0ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "853ce92128d34c91ba466cca5ae36c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a66ce15787414c95abae030df395cc98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab7633239e646c5bafdc7c1655729f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f514fb6d943c4b7683106346c8b4688f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e715a340fa9f46b6832ffb657025451c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b6958ae13884be2afe026ceef3cfc79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fde7728bea9a447b9bac02745b0cd390",
              "IPY_MODEL_b12394c010d949e09aaad8700bd0e8d3",
              "IPY_MODEL_f51fc02867bc43a29113dc3653e171ef"
            ],
            "layout": "IPY_MODEL_00f1782c75544b3cbabb6fa04c715773"
          }
        },
        "fde7728bea9a447b9bac02745b0cd390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55925486fa9f4f8eb7df7ba10f5cf35f",
            "placeholder": "​",
            "style": "IPY_MODEL_6bf9da2236b440eeb390f156319b06a8",
            "value": "config.json: 100%"
          }
        },
        "b12394c010d949e09aaad8700bd0e8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85ccc82ffba24ce58df39cad18dbaf57",
            "max": 677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_725f292bb9204e05a4187628bbd15233",
            "value": 677
          }
        },
        "f51fc02867bc43a29113dc3653e171ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a84a8875a694fbeb789f1cf6ce71da9",
            "placeholder": "​",
            "style": "IPY_MODEL_0bb9f52b2d5e4351b3681bccbdbd5003",
            "value": " 677/677 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "00f1782c75544b3cbabb6fa04c715773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55925486fa9f4f8eb7df7ba10f5cf35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bf9da2236b440eeb390f156319b06a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85ccc82ffba24ce58df39cad18dbaf57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725f292bb9204e05a4187628bbd15233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a84a8875a694fbeb789f1cf6ce71da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb9f52b2d5e4351b3681bccbdbd5003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f060f691b4854ce59d9be912f373e55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9756424b07264f539fbe3102ea7e2a4c",
              "IPY_MODEL_d0974b2830b84985986de79cd0f94de5",
              "IPY_MODEL_679dec99b47642aba89d9d9f8afe8961"
            ],
            "layout": "IPY_MODEL_0dee001b7663465fb23447ffb88d2018"
          }
        },
        "9756424b07264f539fbe3102ea7e2a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afab0042a40745e39986e991fd813c83",
            "placeholder": "​",
            "style": "IPY_MODEL_c03216a9b9394bd690594ba727acfa20",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "d0974b2830b84985986de79cd0f94de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77331dae1b9c4c2eb30224851dfad917",
            "max": 438027135,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fa6bc0bff6b416dbaab4ff549e03fe3",
            "value": 438027135
          }
        },
        "679dec99b47642aba89d9d9f8afe8961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600bf9ec6c23485783618bcd8eb8a55f",
            "placeholder": "​",
            "style": "IPY_MODEL_95bb8c4929e742f8b693377397ef5475",
            "value": " 438M/438M [00:12&lt;00:00, 35.9MB/s]"
          }
        },
        "0dee001b7663465fb23447ffb88d2018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afab0042a40745e39986e991fd813c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03216a9b9394bd690594ba727acfa20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77331dae1b9c4c2eb30224851dfad917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa6bc0bff6b416dbaab4ff549e03fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "600bf9ec6c23485783618bcd8eb8a55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95bb8c4929e742f8b693377397ef5475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c05b62f0bba34f35bfbbaedbe2c1618a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_706c74483f2c41ae9879ba12bb23bb94",
              "IPY_MODEL_d33b7fab7f9d4b78924d81e0af9c9d5c",
              "IPY_MODEL_7af0a12bb82743f1a3aeb8685fe1cb03"
            ],
            "layout": "IPY_MODEL_5a3917f9a49a440a858bdf657cdde9a9"
          }
        },
        "706c74483f2c41ae9879ba12bb23bb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c6d9b88e61b477fa2c01a603656311d",
            "placeholder": "​",
            "style": "IPY_MODEL_7395647c711644fcabc69c1dde483075",
            "value": "model.safetensors: 100%"
          }
        },
        "d33b7fab7f9d4b78924d81e0af9c9d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72123257629f4306946075c5a4e58f71",
            "max": 437965912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d2a0d60b97445c794563bcb85c2d1e6",
            "value": 437965912
          }
        },
        "7af0a12bb82743f1a3aeb8685fe1cb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8bb06ddef384b1986236b5b3ad787c0",
            "placeholder": "​",
            "style": "IPY_MODEL_1d442ce792514ee28c0fbc50eab602e1",
            "value": " 438M/438M [00:17&lt;00:00, 31.7MB/s]"
          }
        },
        "5a3917f9a49a440a858bdf657cdde9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c6d9b88e61b477fa2c01a603656311d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7395647c711644fcabc69c1dde483075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72123257629f4306946075c5a4e58f71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d2a0d60b97445c794563bcb85c2d1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8bb06ddef384b1986236b5b3ad787c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d442ce792514ee28c0fbc50eab602e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96260f9cd42a4aef92915f8006623098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da4526196cac4511bf4435ed07ed166b",
              "IPY_MODEL_412a3af2adac4bcc99584a76c65dbacd",
              "IPY_MODEL_806dfae1fa514f20b9e2b9941f3d9a0d"
            ],
            "layout": "IPY_MODEL_424458084c5d474684b96dd55b209461"
          }
        },
        "da4526196cac4511bf4435ed07ed166b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81374ab52824fc4b549823a3f372a69",
            "placeholder": "​",
            "style": "IPY_MODEL_940cd4e47b0f497ab6541c0c82c78232",
            "value": "vocab.txt: "
          }
        },
        "412a3af2adac4bcc99584a76c65dbacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f6128e8247c485fa18f0050d6913972",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03bf18df713c408682fae96767a20351",
            "value": 1
          }
        },
        "806dfae1fa514f20b9e2b9941f3d9a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b6dcf4f051d43ba869be26f32ce4f2e",
            "placeholder": "​",
            "style": "IPY_MODEL_ce24ab00c79248e6bb4264f8507fe805",
            "value": " 299k/? [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "424458084c5d474684b96dd55b209461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b81374ab52824fc4b549823a3f372a69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940cd4e47b0f497ab6541c0c82c78232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f6128e8247c485fa18f0050d6913972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "03bf18df713c408682fae96767a20351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b6dcf4f051d43ba869be26f32ce4f2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce24ab00c79248e6bb4264f8507fe805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eef87e9e3483470f861fadd8fc4b4a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9290e8e50be249bc89e1898c53ba875d",
              "IPY_MODEL_7fea54de032246feaee1577e2b9fa84e",
              "IPY_MODEL_746fe843c5094b9f84df80b56752b7b9"
            ],
            "layout": "IPY_MODEL_012c9964368345758ca4dd1c8c3f17c7"
          }
        },
        "9290e8e50be249bc89e1898c53ba875d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f07374bd55443ccbd4a16d15e1b402a",
            "placeholder": "​",
            "style": "IPY_MODEL_f40ec04b476d40ee86037fc617564f0c",
            "value": "config.json: 100%"
          }
        },
        "7fea54de032246feaee1577e2b9fa84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d959254f32624fa981857b3040a48d4d",
            "max": 838,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b2323650fd249cfa0e787c259574419",
            "value": 838
          }
        },
        "746fe843c5094b9f84df80b56752b7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e5151d836604318bb47ab2291406087",
            "placeholder": "​",
            "style": "IPY_MODEL_9092c2fd3742401d810cb0b4a718e4a6",
            "value": " 838/838 [00:00&lt;00:00, 42.7kB/s]"
          }
        },
        "012c9964368345758ca4dd1c8c3f17c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f07374bd55443ccbd4a16d15e1b402a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f40ec04b476d40ee86037fc617564f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d959254f32624fa981857b3040a48d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2323650fd249cfa0e787c259574419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e5151d836604318bb47ab2291406087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9092c2fd3742401d810cb0b4a718e4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28adc8e2ad37404aa579aecc8a1b56d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28504b6b818b467a8f31a04e7cfb914c",
              "IPY_MODEL_dca197c538514b35bb92fa38439bc67b",
              "IPY_MODEL_060f7399c76d47de84eab11f583f2097"
            ],
            "layout": "IPY_MODEL_eb26a868781342059436039819a16ec0"
          }
        },
        "28504b6b818b467a8f31a04e7cfb914c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daeea5a33e32479bbf8ac7124e8a0f63",
            "placeholder": "​",
            "style": "IPY_MODEL_46969ebc9f994873b1183c0b2dba17ab",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "dca197c538514b35bb92fa38439bc67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd4e34e8ddf74127b8e26918637f8cd1",
            "max": 435679343,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db78d132702a4e918c0a12d9fbc139d8",
            "value": 435679343
          }
        },
        "060f7399c76d47de84eab11f583f2097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_371c85c5022c413f9ffc8adbac0118f3",
            "placeholder": "​",
            "style": "IPY_MODEL_8eb284fb1a7e4520a929acbb67b8384e",
            "value": " 436M/436M [01:09&lt;00:00, 9.57MB/s]"
          }
        },
        "eb26a868781342059436039819a16ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daeea5a33e32479bbf8ac7124e8a0f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46969ebc9f994873b1183c0b2dba17ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd4e34e8ddf74127b8e26918637f8cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db78d132702a4e918c0a12d9fbc139d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "371c85c5022c413f9ffc8adbac0118f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eb284fb1a7e4520a929acbb67b8384e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "690d945a7e7948e5ae63684a15d0c107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7779a525919d4581a1938d69fbed72b4",
              "IPY_MODEL_9c8a568b0c3e49398d3a86110d70c3f7",
              "IPY_MODEL_a91d313b565a4a7d88886ced8d37ac4d"
            ],
            "layout": "IPY_MODEL_3fb6497b4feb43e0aa2d19effa992027"
          }
        },
        "7779a525919d4581a1938d69fbed72b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee195ed045594d6094754988b9382356",
            "placeholder": "​",
            "style": "IPY_MODEL_cd7cfe5b922b4a6d939b799745e6684b",
            "value": "model.safetensors: 100%"
          }
        },
        "9c8a568b0c3e49398d3a86110d70c3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60adf7a6b2de4b79bf5e6aa257516f4a",
            "max": 435618728,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8eda984b6cdf463585a8ed50ef967d92",
            "value": 435618728
          }
        },
        "a91d313b565a4a7d88886ced8d37ac4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d46f66d216554a4189105ed92d62290f",
            "placeholder": "​",
            "style": "IPY_MODEL_66b3e528c502476db26b7eeda515ee76",
            "value": " 436M/436M [00:11&lt;00:00, 77.5MB/s]"
          }
        },
        "3fb6497b4feb43e0aa2d19effa992027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee195ed045594d6094754988b9382356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd7cfe5b922b4a6d939b799745e6684b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60adf7a6b2de4b79bf5e6aa257516f4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eda984b6cdf463585a8ed50ef967d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d46f66d216554a4189105ed92d62290f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b3e528c502476db26b7eeda515ee76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4f001318f0b48d9bf03e8f2f55ce10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bfc84f1ee31436cbde89bdd05f082aa",
              "IPY_MODEL_895b6fd27eb2419fb64512967745c02c",
              "IPY_MODEL_5774ad648b9249c8b709c87d688320cf"
            ],
            "layout": "IPY_MODEL_428e0480daf447dd8ac9bd4575bf5a09"
          }
        },
        "7bfc84f1ee31436cbde89bdd05f082aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e1845a6c6c742f2b5f432c34c542074",
            "placeholder": "​",
            "style": "IPY_MODEL_e2a39d9306494bb38f4110c63228ade6",
            "value": "vocab.txt: "
          }
        },
        "895b6fd27eb2419fb64512967745c02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c628d119d8154d4dba79cd0e5ff12e6c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c61ef5a2ab340ddbc5a2f1dbcf22ece",
            "value": 1
          }
        },
        "5774ad648b9249c8b709c87d688320cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71f0e6e4787414f9f9a228353800923",
            "placeholder": "​",
            "style": "IPY_MODEL_eacaac1e0e284a78a02066183b548b54",
            "value": " 299k/? [00:00&lt;00:00, 3.25MB/s]"
          }
        },
        "428e0480daf447dd8ac9bd4575bf5a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1845a6c6c742f2b5f432c34c542074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a39d9306494bb38f4110c63228ade6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c628d119d8154d4dba79cd0e5ff12e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7c61ef5a2ab340ddbc5a2f1dbcf22ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b71f0e6e4787414f9f9a228353800923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacaac1e0e284a78a02066183b548b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2c0a1da161b491a82401f3de01786ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66bdc24e84a640a7a6a645fb2cf6e715",
              "IPY_MODEL_9211ef99eff643eba0664a0a498c1b14",
              "IPY_MODEL_947360425c66485e8049cc0a206eed89"
            ],
            "layout": "IPY_MODEL_f00796c13e6c47d195100459bd21a1c4"
          }
        },
        "66bdc24e84a640a7a6a645fb2cf6e715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb2eb47d10844eccbb93f029457dd3aa",
            "placeholder": "​",
            "style": "IPY_MODEL_11bc56f114e4469fa81e75d449e9b38b",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "9211ef99eff643eba0664a0a498c1b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2706ff571b9487a9f38629ac5832a31",
            "max": 290,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b69605eaac774224b3135c9451018460",
            "value": 290
          }
        },
        "947360425c66485e8049cc0a206eed89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9829750590cd421499a5d4b26e5862bb",
            "placeholder": "​",
            "style": "IPY_MODEL_7a16408fc7a64da4b4a0962c0f3e3933",
            "value": " 290/290 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "f00796c13e6c47d195100459bd21a1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2eb47d10844eccbb93f029457dd3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11bc56f114e4469fa81e75d449e9b38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2706ff571b9487a9f38629ac5832a31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69605eaac774224b3135c9451018460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9829750590cd421499a5d4b26e5862bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a16408fc7a64da4b4a0962c0f3e3933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b9ae152c60b4a31aa4f0032c453755f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f003414a3df4562a2baf72ada1ab6c9",
              "IPY_MODEL_3afa2264692c493bbefcb5456232f948",
              "IPY_MODEL_b259348fbb3a41688bcc2f4a20e20282"
            ],
            "layout": "IPY_MODEL_58d9a0b191c649b3ad2d96178bc1c927"
          }
        },
        "8f003414a3df4562a2baf72ada1ab6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6218ff177486469d9976506fc32aca06",
            "placeholder": "​",
            "style": "IPY_MODEL_5121e8b2912248cc9b26b52aa64aac91",
            "value": "config.json: "
          }
        },
        "3afa2264692c493bbefcb5456232f948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38fb1d167a248cfbb6368e92997011c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_849e10abe64a46eab7c2d66511e70f2c",
            "value": 1
          }
        },
        "b259348fbb3a41688bcc2f4a20e20282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e59da3aba7c44e259e0ed1b9f42734a9",
            "placeholder": "​",
            "style": "IPY_MODEL_dd5d512f287e45d284b60cb879c7379a",
            "value": " 4.59k/? [00:00&lt;00:00, 263kB/s]"
          }
        },
        "58d9a0b191c649b3ad2d96178bc1c927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6218ff177486469d9976506fc32aca06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5121e8b2912248cc9b26b52aa64aac91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e38fb1d167a248cfbb6368e92997011c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "849e10abe64a46eab7c2d66511e70f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e59da3aba7c44e259e0ed1b9f42734a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5d512f287e45d284b60cb879c7379a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "879e2d795cab44f99f9ad9c72d94d153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba5429369269456bafc23d28964685ee",
              "IPY_MODEL_ba8427f07b2f4aa89a8e344e3b891d34",
              "IPY_MODEL_6415ec86d0e44e129a8e077f5bcf18fd"
            ],
            "layout": "IPY_MODEL_adfd39a27f154a97aad0ccd104835d6d"
          }
        },
        "ba5429369269456bafc23d28964685ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca3b22f9a3e46828dc3e195e1d25a42",
            "placeholder": "​",
            "style": "IPY_MODEL_cf154e1fe63d425dbc954e6179111893",
            "value": "model.safetensors: 100%"
          }
        },
        "ba8427f07b2f4aa89a8e344e3b891d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32affaf3ceb24aeea181b962e08bc6cd",
            "max": 166587896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b6f3e95e6bb4ef7abc894eeeddc299c",
            "value": 166587896
          }
        },
        "6415ec86d0e44e129a8e077f5bcf18fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6c112fad5c41fbbb3b58ee840660d8",
            "placeholder": "​",
            "style": "IPY_MODEL_350b72ba8ed24f70b65b42fdb67d803a",
            "value": " 167M/167M [00:02&lt;00:00, 116MB/s]"
          }
        },
        "adfd39a27f154a97aad0ccd104835d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca3b22f9a3e46828dc3e195e1d25a42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf154e1fe63d425dbc954e6179111893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32affaf3ceb24aeea181b962e08bc6cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6f3e95e6bb4ef7abc894eeeddc299c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d6c112fad5c41fbbb3b58ee840660d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "350b72ba8ed24f70b65b42fdb67d803a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95f43315cb76414388eefe39faa10c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa07ce966cb347ef8a8392e33c85a470",
              "IPY_MODEL_94a0bf7ab4954c3d81c0241014e53720",
              "IPY_MODEL_1ffa3927a2244eea9b9f79f5047083d6"
            ],
            "layout": "IPY_MODEL_e6a40ab775994146b8f7095ada3b8d25"
          }
        },
        "fa07ce966cb347ef8a8392e33c85a470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e498e8756f84eb7a8f45b827cf2909a",
            "placeholder": "​",
            "style": "IPY_MODEL_23bf9393b80a4b218756171f624e3992",
            "value": "model.safetensors: 100%"
          }
        },
        "94a0bf7ab4954c3d81c0241014e53720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad71954fe361464ca13bce130d1dec99",
            "max": 102469840,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c350c30d39d4d34bad0062371fcbd75",
            "value": 102469840
          }
        },
        "1ffa3927a2244eea9b9f79f5047083d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_155169cba80e4a909288d39b7ab02fb5",
            "placeholder": "​",
            "style": "IPY_MODEL_8f35cbf1789140079aef3bf9b3368c54",
            "value": " 102M/102M [00:04&lt;00:00, 17.3MB/s]"
          }
        },
        "e6a40ab775994146b8f7095ada3b8d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e498e8756f84eb7a8f45b827cf2909a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23bf9393b80a4b218756171f624e3992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad71954fe361464ca13bce130d1dec99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c350c30d39d4d34bad0062371fcbd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "155169cba80e4a909288d39b7ab02fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f35cbf1789140079aef3bf9b3368c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3e112bc90fb46b38cc43e7ebee259bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f129ebc087a64613b7b2e87239d36df0",
              "IPY_MODEL_37e98402400248b4bdab02c3a77d218d",
              "IPY_MODEL_2d0e280b520b42a4b00ca07ff4c991c1"
            ],
            "layout": "IPY_MODEL_1f71550e58494d97813dcd0218c5e940"
          }
        },
        "f129ebc087a64613b7b2e87239d36df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3335985fb264ac3961b1f6b01d1fb06",
            "placeholder": "​",
            "style": "IPY_MODEL_93dee78acd204a7fa5cd7f1799742953",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "37e98402400248b4bdab02c3a77d218d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e42da2434934871bebc46e3d1c9a23e",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_018b8a71388240ab8fe8ad547f05961a",
            "value": 287
          }
        },
        "2d0e280b520b42a4b00ca07ff4c991c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12c7a185cac04efaad8aceddb0bcd00f",
            "placeholder": "​",
            "style": "IPY_MODEL_cc6c46715bec457d958f73e5b022152e",
            "value": " 287/287 [00:00&lt;00:00, 15.1kB/s]"
          }
        },
        "1f71550e58494d97813dcd0218c5e940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3335985fb264ac3961b1f6b01d1fb06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93dee78acd204a7fa5cd7f1799742953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e42da2434934871bebc46e3d1c9a23e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "018b8a71388240ab8fe8ad547f05961a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12c7a185cac04efaad8aceddb0bcd00f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc6c46715bec457d958f73e5b022152e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a02a998ce664f50b327cd21db218ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c76b656954df49d1b98729837ba8df69",
              "IPY_MODEL_f0353be70e414c0e89958ee576a1e470",
              "IPY_MODEL_251e3cbb7127466c9f9b5f85f83868b6"
            ],
            "layout": "IPY_MODEL_4d6863d691674c178c806266cdc43963"
          }
        },
        "c76b656954df49d1b98729837ba8df69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d6f894b9f14068b869a2c6d2804e1d",
            "placeholder": "​",
            "style": "IPY_MODEL_205cf9eb218a4cfba805864997f802d8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f0353be70e414c0e89958ee576a1e470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af3d68e5ad26451da4908b0626f0634e",
            "max": 506,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4faa6c07bba4cea866edf015f8b7d60",
            "value": 506
          }
        },
        "251e3cbb7127466c9f9b5f85f83868b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78891c08c12648b6b56560afc2083848",
            "placeholder": "​",
            "style": "IPY_MODEL_0381fcf17f944943bc682088e2cc3415",
            "value": " 506/506 [00:00&lt;00:00, 37.9kB/s]"
          }
        },
        "4d6863d691674c178c806266cdc43963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d6f894b9f14068b869a2c6d2804e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "205cf9eb218a4cfba805864997f802d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af3d68e5ad26451da4908b0626f0634e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4faa6c07bba4cea866edf015f8b7d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78891c08c12648b6b56560afc2083848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0381fcf17f944943bc682088e2cc3415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c82bf322d7574b7c803e767c0ff8bae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8668fee75c9c4a0b997b2fc662542491",
              "IPY_MODEL_06942a3261124f0eba51228f2284d95a",
              "IPY_MODEL_375eeaefb2204ab091498880244e5339"
            ],
            "layout": "IPY_MODEL_9e9df74c4db44772b02e990cfdfe01b1"
          }
        },
        "8668fee75c9c4a0b997b2fc662542491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b84f2bba002448baf2bb63c811e9ad5",
            "placeholder": "​",
            "style": "IPY_MODEL_76f4268d44ee42bab35c6e042ddae8a7",
            "value": "vocab.txt: "
          }
        },
        "06942a3261124f0eba51228f2284d95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab41a5e445f4909983dd8e5b25c9fe1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7240cc9041be466baad6c24e90de7f10",
            "value": 1
          }
        },
        "375eeaefb2204ab091498880244e5339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed8f5c71e3c45499e6d41f41d90dc12",
            "placeholder": "​",
            "style": "IPY_MODEL_da246495a87f45468de5bd5571b30a14",
            "value": " 232k/? [00:00&lt;00:00, 17.7MB/s]"
          }
        },
        "9e9df74c4db44772b02e990cfdfe01b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b84f2bba002448baf2bb63c811e9ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f4268d44ee42bab35c6e042ddae8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bab41a5e445f4909983dd8e5b25c9fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7240cc9041be466baad6c24e90de7f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ed8f5c71e3c45499e6d41f41d90dc12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da246495a87f45468de5bd5571b30a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ed231e81e244b81900d503c065ae836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_210017003e664591937cb71ebc3fa54c",
              "IPY_MODEL_c07e723b094c46129f66496a99315c64",
              "IPY_MODEL_0d37fa6c76bd46e78739e6780031b213"
            ],
            "layout": "IPY_MODEL_8e5b4fed93984be7bdb7aa96000fa7fb"
          }
        },
        "210017003e664591937cb71ebc3fa54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1388a96f8b74d4ab524af0d0fe377c7",
            "placeholder": "​",
            "style": "IPY_MODEL_681a006142c94e03b4d35677b3b66f78",
            "value": "tokenizer.json: "
          }
        },
        "c07e723b094c46129f66496a99315c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73e39679513e41898b404afc11f9259c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dfd2463362441f1b524105d47d12bd6",
            "value": 1
          }
        },
        "0d37fa6c76bd46e78739e6780031b213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61682d66225640a791c5ec00b2970867",
            "placeholder": "​",
            "style": "IPY_MODEL_92a804b17bc74bebba543b4049e56142",
            "value": " 711k/? [00:00&lt;00:00, 45.1MB/s]"
          }
        },
        "8e5b4fed93984be7bdb7aa96000fa7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1388a96f8b74d4ab524af0d0fe377c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681a006142c94e03b4d35677b3b66f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e39679513e41898b404afc11f9259c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4dfd2463362441f1b524105d47d12bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61682d66225640a791c5ec00b2970867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a804b17bc74bebba543b4049e56142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2241675bcd734188864780ca8f35e48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c90f0c7a58f94ffab84145255256720b",
              "IPY_MODEL_b6fbe67213ba466b860e3a659bfe6505",
              "IPY_MODEL_570b90c852ab493b9402597835bf7ce9"
            ],
            "layout": "IPY_MODEL_7e1b05b3b0f4496696a979f3f7caaf1e"
          }
        },
        "c90f0c7a58f94ffab84145255256720b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_990f2d7b6913499d91e2c997d27fe6e1",
            "placeholder": "​",
            "style": "IPY_MODEL_e3716ff6439d4c46a65860c447a155d7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b6fbe67213ba466b860e3a659bfe6505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bedf1de5f4ad4450b81130de59014462",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef6b1d8c93504b929cb2822f2e4ade6e",
            "value": 125
          }
        },
        "570b90c852ab493b9402597835bf7ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_867b657f56a14dc1b3ac451f332d3434",
            "placeholder": "​",
            "style": "IPY_MODEL_3644ab5ec65e4b32a75fb2dabd9086ca",
            "value": " 125/125 [00:00&lt;00:00, 7.77kB/s]"
          }
        },
        "7e1b05b3b0f4496696a979f3f7caaf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990f2d7b6913499d91e2c997d27fe6e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3716ff6439d4c46a65860c447a155d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bedf1de5f4ad4450b81130de59014462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef6b1d8c93504b929cb2822f2e4ade6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "867b657f56a14dc1b3ac451f332d3434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3644ab5ec65e4b32a75fb2dabd9086ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09c2c38823084975bb73f2cb84b6ceb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5c0691b411a453ea276d0f63cbe702c",
              "IPY_MODEL_1db59ff5e9c84c68855df6cdbbd9ec02",
              "IPY_MODEL_cfaf24077c48400ab747d047ba511896"
            ],
            "layout": "IPY_MODEL_ca7c9548a58645e7b704afb9b1f851b5"
          }
        },
        "b5c0691b411a453ea276d0f63cbe702c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9fbd1d7abe74d2baa43fef390a63f6b",
            "placeholder": "​",
            "style": "IPY_MODEL_5d848f6ca92b42dfbe3f0dac5ab5ca1a",
            "value": "config.json: "
          }
        },
        "1db59ff5e9c84c68855df6cdbbd9ec02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a9a73eb53cd4854bbdf38e86c8f3ef6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7f1e4c0af5e40ed93b00e23292d8c17",
            "value": 1
          }
        },
        "cfaf24077c48400ab747d047ba511896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8adfcaa0ab124783ac5fe54d9141da49",
            "placeholder": "​",
            "style": "IPY_MODEL_0345127f6f994ee0827024635b89c283",
            "value": " 4.56k/? [00:00&lt;00:00, 430kB/s]"
          }
        },
        "ca7c9548a58645e7b704afb9b1f851b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9fbd1d7abe74d2baa43fef390a63f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d848f6ca92b42dfbe3f0dac5ab5ca1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a9a73eb53cd4854bbdf38e86c8f3ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c7f1e4c0af5e40ed93b00e23292d8c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8adfcaa0ab124783ac5fe54d9141da49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0345127f6f994ee0827024635b89c283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "107eb42c42ed464da9bbb76cebf0299a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b53df76e0c344d91911a15a4d00f851c",
              "IPY_MODEL_a4feefb75c1545eea2ad79751228592b",
              "IPY_MODEL_57199fdaa44a4e8fb152b9be98e6fa7e"
            ],
            "layout": "IPY_MODEL_f8a464a63f0f4c53854f50dd71ed4867"
          }
        },
        "b53df76e0c344d91911a15a4d00f851c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ee9249cf104fbba4259cc587d09798",
            "placeholder": "​",
            "style": "IPY_MODEL_6d5945eadd20492b9f31952dd24c6da8",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "a4feefb75c1545eea2ad79751228592b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a39eb04b0bc420b9cce9d348842cfc7",
            "max": 989820849,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fb88904db73420b988fbcbaa76c5841",
            "value": 989820849
          }
        },
        "57199fdaa44a4e8fb152b9be98e6fa7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1af8032c0fa48d391ffaad2ee6cff9a",
            "placeholder": "​",
            "style": "IPY_MODEL_64add1fc29f04f95811d12e2633a971e",
            "value": " 990M/990M [00:17&lt;00:00, 86.0MB/s]"
          }
        },
        "f8a464a63f0f4c53854f50dd71ed4867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40ee9249cf104fbba4259cc587d09798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d5945eadd20492b9f31952dd24c6da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a39eb04b0bc420b9cce9d348842cfc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fb88904db73420b988fbcbaa76c5841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1af8032c0fa48d391ffaad2ee6cff9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64add1fc29f04f95811d12e2633a971e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebcdd896f05f4423b67ce83a01f855df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c83eda79cdd647458bea4d219b2f9936",
              "IPY_MODEL_d78a2049758b4ef4baa533025e71c0e5",
              "IPY_MODEL_07997443d0754de99ac6a65970b9ec89"
            ],
            "layout": "IPY_MODEL_7750eb565e944468a992882709bf4353"
          }
        },
        "c83eda79cdd647458bea4d219b2f9936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56fa6e6940d74df9b188cd8df4ed0e08",
            "placeholder": "​",
            "style": "IPY_MODEL_4687dc2c482140cca973bff76160eeb5",
            "value": "model.safetensors: 100%"
          }
        },
        "d78a2049758b4ef4baa533025e71c0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8314f2e31864f23aa11eda011abfdb1",
            "max": 989721336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adb7a9b0cb0448c1a2f71898ad38c9a8",
            "value": 989721336
          }
        },
        "07997443d0754de99ac6a65970b9ec89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9432bcd2b961472cb1587e981c07f6f1",
            "placeholder": "​",
            "style": "IPY_MODEL_5bb63b711c824f9ab3a5bea1cd9de396",
            "value": " 990M/990M [00:35&lt;00:00, 37.1MB/s]"
          }
        },
        "7750eb565e944468a992882709bf4353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56fa6e6940d74df9b188cd8df4ed0e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4687dc2c482140cca973bff76160eeb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8314f2e31864f23aa11eda011abfdb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb7a9b0cb0448c1a2f71898ad38c9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9432bcd2b961472cb1587e981c07f6f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb63b711c824f9ab3a5bea1cd9de396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e0b45610d8c459ea5e32242b4c7b083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c095127dd3634182b19629b0a9c930ad",
              "IPY_MODEL_5215432d14c34974ab393afe3cc56974",
              "IPY_MODEL_24b6c0a4959549eab3185de2af15b061"
            ],
            "layout": "IPY_MODEL_47b10f6105204a8ba4b76876c8b2758a"
          }
        },
        "c095127dd3634182b19629b0a9c930ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76e584b467b46df97de42b732b04cdb",
            "placeholder": "​",
            "style": "IPY_MODEL_3336812d244b49c78e3bf60e8cdd491f",
            "value": "config.json: "
          }
        },
        "5215432d14c34974ab393afe3cc56974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_422b26a0fac54763b88ddc428b21e062",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ee0d9a1234449f1b0861d64e01c0611",
            "value": 1
          }
        },
        "24b6c0a4959549eab3185de2af15b061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b333eb4023bd4cf2b714ced1bd0ba227",
            "placeholder": "​",
            "style": "IPY_MODEL_e6560aabc5b545788f468945e7946349",
            "value": " 136k/? [00:00&lt;00:00, 9.55MB/s]"
          }
        },
        "47b10f6105204a8ba4b76876c8b2758a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c76e584b467b46df97de42b732b04cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3336812d244b49c78e3bf60e8cdd491f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422b26a0fac54763b88ddc428b21e062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6ee0d9a1234449f1b0861d64e01c0611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b333eb4023bd4cf2b714ced1bd0ba227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6560aabc5b545788f468945e7946349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05d7ea54854f42aca07b2df08d828fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10c5985311964bc885eb445040c4caac",
              "IPY_MODEL_540ad51671d746d984ad8522d38b3221",
              "IPY_MODEL_c5c3bff9ac524095a469f2797d02a7d9"
            ],
            "layout": "IPY_MODEL_a8f03461df3c4cf4b9ceb2c6e2857efb"
          }
        },
        "10c5985311964bc885eb445040c4caac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4afc20c0cda4f35bef211b855567c07",
            "placeholder": "​",
            "style": "IPY_MODEL_ff33399ec6cb49b99c527363dd2b8188",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "540ad51671d746d984ad8522d38b3221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f724b69036dc46dba2e1a29da6df374e",
            "max": 470435927,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b07d3dc9c334e8e8b823cab116c1eaa",
            "value": 470435927
          }
        },
        "c5c3bff9ac524095a469f2797d02a7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60403a0cc4564c3c9add21fe171d4f92",
            "placeholder": "​",
            "style": "IPY_MODEL_84a1de907db646eca0edc267015732f0",
            "value": " 470M/470M [00:09&lt;00:00, 14.5MB/s]"
          }
        },
        "a8f03461df3c4cf4b9ceb2c6e2857efb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4afc20c0cda4f35bef211b855567c07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff33399ec6cb49b99c527363dd2b8188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f724b69036dc46dba2e1a29da6df374e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b07d3dc9c334e8e8b823cab116c1eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60403a0cc4564c3c9add21fe171d4f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84a1de907db646eca0edc267015732f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec07519818274418844c655993bc4b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aa6cd3a19724a23b7e5279eea2a4dfd",
              "IPY_MODEL_a5cb58a8310444f18f5b7cdedd800cf5",
              "IPY_MODEL_d8400dd87b6f4c58a7eccdbc7991c91b"
            ],
            "layout": "IPY_MODEL_efb8e7cc8ada47efb8067094aa962a12"
          }
        },
        "2aa6cd3a19724a23b7e5279eea2a4dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e4db92803e64a6f932c0f46cd92385f",
            "placeholder": "​",
            "style": "IPY_MODEL_d74c7420264a4b8da605c468c0b06e64",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a5cb58a8310444f18f5b7cdedd800cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e085438ec847f2ae89221608cf0d4f",
            "max": 320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_445a4cffa359475b9dda98077d3b597f",
            "value": 320
          }
        },
        "d8400dd87b6f4c58a7eccdbc7991c91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fa53bf05994ff2a3d894d5285c98a6",
            "placeholder": "​",
            "style": "IPY_MODEL_ddbcc1512ffa49a4ba73a10aa25f9dc8",
            "value": " 320/320 [00:00&lt;00:00, 18.8kB/s]"
          }
        },
        "efb8e7cc8ada47efb8067094aa962a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4db92803e64a6f932c0f46cd92385f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74c7420264a4b8da605c468c0b06e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57e085438ec847f2ae89221608cf0d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "445a4cffa359475b9dda98077d3b597f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5fa53bf05994ff2a3d894d5285c98a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbcc1512ffa49a4ba73a10aa25f9dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a190b341058f47aa9d93d8a6afac664f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b882ae448184812a6ef8aab8aa0e50f",
              "IPY_MODEL_badfd2540485431fb0398b7d195ec251",
              "IPY_MODEL_f632c62d944b405589f40e5c27713f22"
            ],
            "layout": "IPY_MODEL_6896128c5f314dae95374ff5119ff88e"
          }
        },
        "7b882ae448184812a6ef8aab8aa0e50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b23d627a85de4c9ca09ce2b0ec6405ec",
            "placeholder": "​",
            "style": "IPY_MODEL_9df34b1d83384320b8df2664fed12601",
            "value": "model.safetensors: 100%"
          }
        },
        "badfd2540485431fb0398b7d195ec251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ae6f966e5849fbbd8fb20dc27c84e8",
            "max": 470379396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e93adcbd4304f3d81f1e60db082ca7d",
            "value": 470379396
          }
        },
        "f632c62d944b405589f40e5c27713f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f839b1707ee84682b70f00ebf202cdd2",
            "placeholder": "​",
            "style": "IPY_MODEL_1f90bae00700466c893e10ce5ea3773d",
            "value": " 470M/470M [00:08&lt;00:00, 47.1MB/s]"
          }
        },
        "6896128c5f314dae95374ff5119ff88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b23d627a85de4c9ca09ce2b0ec6405ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df34b1d83384320b8df2664fed12601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9ae6f966e5849fbbd8fb20dc27c84e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e93adcbd4304f3d81f1e60db082ca7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f839b1707ee84682b70f00ebf202cdd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f90bae00700466c893e10ce5ea3773d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6aa75119cd24010a891623c5575f1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0096689a338470b8876a3c6b0ccd5d5",
              "IPY_MODEL_a448c039b7c646faac7d8481b6fe856d",
              "IPY_MODEL_928ef5f6b979422fba58299f8940a200"
            ],
            "layout": "IPY_MODEL_914f8d73c8574ead902a233a2869b181"
          }
        },
        "d0096689a338470b8876a3c6b0ccd5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f3718c9d2c41af90172bee379a700f",
            "placeholder": "​",
            "style": "IPY_MODEL_35261eb3612d4a8a94470e77e489d174",
            "value": "vocab.txt: "
          }
        },
        "a448c039b7c646faac7d8481b6fe856d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2adc99b82b8b4b88bd70babf2b3513f4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2fe819347244fa0ad44bcecc4d3bdfe",
            "value": 1
          }
        },
        "928ef5f6b979422fba58299f8940a200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03a86bc85ba84e778e2d64b0a553fdda",
            "placeholder": "​",
            "style": "IPY_MODEL_1bb4f7badf344b09bc01f51ac7bbe14e",
            "value": " 232k/? [00:00&lt;00:00, 7.54MB/s]"
          }
        },
        "914f8d73c8574ead902a233a2869b181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f3718c9d2c41af90172bee379a700f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35261eb3612d4a8a94470e77e489d174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2adc99b82b8b4b88bd70babf2b3513f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c2fe819347244fa0ad44bcecc4d3bdfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03a86bc85ba84e778e2d64b0a553fdda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb4f7badf344b09bc01f51ac7bbe14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4429058a80214d77a8e4abdd03cbc08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec6985a1a9ac4a9eb290c1c365b3b790",
              "IPY_MODEL_b8af1793c3fe4a4894d00f04311286f5",
              "IPY_MODEL_129b5a7f1e3f4cd88486ca2d4271f810"
            ],
            "layout": "IPY_MODEL_ebb9daf3010c49b6bf00a7a9f9c034b3"
          }
        },
        "ec6985a1a9ac4a9eb290c1c365b3b790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7784d254310d490785f68d1c0f2d897a",
            "placeholder": "​",
            "style": "IPY_MODEL_40272faad7834c8cb95ffbaf98e1e589",
            "value": "tokenizer.json: "
          }
        },
        "b8af1793c3fe4a4894d00f04311286f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3124ef25f35640578220efdd84b1d978",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0f58d47f4e44a959b6e086a7edad5ba",
            "value": 1
          }
        },
        "129b5a7f1e3f4cd88486ca2d4271f810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd3573bbf4c74513bed9cf3f50e5072a",
            "placeholder": "​",
            "style": "IPY_MODEL_7d305df06e4e4e03a6b71796564e58e4",
            "value": " 466k/? [00:00&lt;00:00, 11.6MB/s]"
          }
        },
        "ebb9daf3010c49b6bf00a7a9f9c034b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7784d254310d490785f68d1c0f2d897a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40272faad7834c8cb95ffbaf98e1e589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3124ef25f35640578220efdd84b1d978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a0f58d47f4e44a959b6e086a7edad5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd3573bbf4c74513bed9cf3f50e5072a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d305df06e4e4e03a6b71796564e58e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5044d36ed4a46f1b22ce5232581cb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87f3ebd1900e41baa4ffb2775374f0ca",
              "IPY_MODEL_f29b4749439d41ed9488326ed5cfca11",
              "IPY_MODEL_e4eb70ca0a7c43759795a5a283df04ad"
            ],
            "layout": "IPY_MODEL_9f00de29822647e386a78c1ce907024d"
          }
        },
        "87f3ebd1900e41baa4ffb2775374f0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7002f2b4194189b13bfc7c47cd4d16",
            "placeholder": "​",
            "style": "IPY_MODEL_b30a8413a2364edfac3c323d0bba643e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f29b4749439d41ed9488326ed5cfca11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc823cf8a950454cb3e128ad36877bb4",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68d941fe71d6424eae43a6aee2d2a5f2",
            "value": 112
          }
        },
        "e4eb70ca0a7c43759795a5a283df04ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7047a27be47042f7b5083b6b290dc11d",
            "placeholder": "​",
            "style": "IPY_MODEL_fa9d7d08ac0944cb9c7ec5a2fab4cd12",
            "value": " 112/112 [00:00&lt;00:00, 4.00kB/s]"
          }
        },
        "9f00de29822647e386a78c1ce907024d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7002f2b4194189b13bfc7c47cd4d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b30a8413a2364edfac3c323d0bba643e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc823cf8a950454cb3e128ad36877bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d941fe71d6424eae43a6aee2d2a5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7047a27be47042f7b5083b6b290dc11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9d7d08ac0944cb9c7ec5a2fab4cd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f0de0e218e43a1ac4b90c545999f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_900c04ba2b03483a9e578337f0d71ac0",
              "IPY_MODEL_5d2a14cce54448a3bb8b0f2459a93d28",
              "IPY_MODEL_c9eec94034404ff18043936a6f7756de"
            ],
            "layout": "IPY_MODEL_435cce18c9b54a96b4f1196517572dd0"
          }
        },
        "900c04ba2b03483a9e578337f0d71ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9347e8460dfd455bb41dfd7fbef5db9f",
            "placeholder": "​",
            "style": "IPY_MODEL_b7daf82b0831432b955d2e3d12517012",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "5d2a14cce54448a3bb8b0f2459a93d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_437c130a16ae4d7c984856e31ac5134c",
            "max": 251,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26afedf9a27d45f588d4fbd16e3dbe6d",
            "value": 251
          }
        },
        "c9eec94034404ff18043936a6f7756de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de7c70c724ad4cb2ab1097f5cd53901b",
            "placeholder": "​",
            "style": "IPY_MODEL_a9b4daf88a7f4454a1cc1bf719c34b4b",
            "value": " 251/251 [00:00&lt;00:00, 17.5kB/s]"
          }
        },
        "435cce18c9b54a96b4f1196517572dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9347e8460dfd455bb41dfd7fbef5db9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7daf82b0831432b955d2e3d12517012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "437c130a16ae4d7c984856e31ac5134c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26afedf9a27d45f588d4fbd16e3dbe6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de7c70c724ad4cb2ab1097f5cd53901b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9b4daf88a7f4454a1cc1bf719c34b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8351484549f643dc8c0d8d91a7499913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_7a85ee82f8fc4732848c5bf7a751847e"
          }
        },
        "ed176921933c43dcbc7fcb9fb5d8901c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d47198aecb9347cd9e7824057a1f3372",
            "placeholder": "​",
            "style": "IPY_MODEL_c237576e479e48a897262fbdc6c88c6a",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "2fda62722f1b4510b2cea75ffe2ce114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9f5bc4d882254f859bd1476308f7f8f3",
            "placeholder": "​",
            "style": "IPY_MODEL_a9eb859ccf7c423894dfa07bb6cc540e",
            "value": ""
          }
        },
        "a65d95e6435349d8892b189346768d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_29cac26a4b59434eb8fd5034a12702e6",
            "style": "IPY_MODEL_0a71a013d0754ff588359b343c36f88f",
            "value": true
          }
        },
        "1634b4b016aa4dabada18f2a364e95ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4c658c16b3ff4af49e3270bac5c417e8",
            "style": "IPY_MODEL_c518f231023044e9a6e221e73c6487cd",
            "tooltip": ""
          }
        },
        "c05f94f1ad0545dc8eee560fda5413ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f37a109a69e54a02b2c11a122f373cca",
            "placeholder": "​",
            "style": "IPY_MODEL_65208dd07b1d4d75b0724f28404827c5",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7a85ee82f8fc4732848c5bf7a751847e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d47198aecb9347cd9e7824057a1f3372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c237576e479e48a897262fbdc6c88c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5bc4d882254f859bd1476308f7f8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9eb859ccf7c423894dfa07bb6cc540e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29cac26a4b59434eb8fd5034a12702e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a71a013d0754ff588359b343c36f88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c658c16b3ff4af49e3270bac5c417e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c518f231023044e9a6e221e73c6487cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f37a109a69e54a02b2c11a122f373cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65208dd07b1d4d75b0724f28404827c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae637646f5a54f3a852efbdaa13fc000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0e578959424355b81ed076489e20af",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc80f9c10fc4006a587f119d66df5a5",
            "value": "Connecting..."
          }
        },
        "fe0e578959424355b81ed076489e20af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc80f9c10fc4006a587f119d66df5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgFJR8aEmFxK",
        "outputId": "84c95a14-e254-404f-88e1-4cf9b8e3fcc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyluach\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyluach\n",
            "Successfully installed pyluach-2.2.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dictionaries-common hunspell-en-us libhunspell-1.7-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  ispell | aspell | hunspell wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core\n",
            "The following NEW packages will be installed:\n",
            "  dictionaries-common hunspell-en-us libhunspell-1.7-0 libhunspell-dev\n",
            "  libtext-iconv-perl\n",
            "0 upgraded, 5 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 896 kB of archives.\n",
            "After this operation, 3,130 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtext-iconv-perl amd64 1.7-7build3 [14.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 dictionaries-common all 1.28.14 [185 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 hunspell-en-us all 1:2020.12.07-2 [280 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhunspell-1.7-0 amd64 1.7.0-4build1 [175 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhunspell-dev amd64 1.7.0-4build1 [241 kB]\n",
            "Fetched 896 kB in 1s (1,368 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 126371 files and directories currently installed.)\n",
            "Preparing to unpack .../libtext-iconv-perl_1.7-7build3_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-7build3) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../dictionaries-common_1.28.14_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.28.14) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../hunspell-en-us_1%3a2020.12.07-2_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2020.12.07-2) ...\n",
            "Selecting previously unselected package libhunspell-1.7-0:amd64.\n",
            "Preparing to unpack .../libhunspell-1.7-0_1.7.0-4build1_amd64.deb ...\n",
            "Unpacking libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\n",
            "Selecting previously unselected package libhunspell-dev:amd64.\n",
            "Preparing to unpack .../libhunspell-dev_1.7.0-4build1_amd64.deb ...\n",
            "Unpacking libhunspell-dev:amd64 (1.7.0-4build1) ...\n",
            "Setting up libtext-iconv-perl (1.7-7build3) ...\n",
            "Setting up dictionaries-common (1.28.14) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up hunspell-en-us (1:2020.12.07-2) ...\n",
            "Setting up libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\n",
            "Setting up libhunspell-dev:amd64 (1.7.0-4build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for dictionaries-common (1.28.14) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.3-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pyspellchecker-0.8.3-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.3\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (11.3.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-heb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 432 kB of archives.\n",
            "After this operation, 976 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-heb all 1:4.00~git30-7274cfa-1.1 [432 kB]\n",
            "Fetched 432 kB in 1s (377 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-heb.\n",
            "(Reading database ... 126482 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-heb_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-heb (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-heb (1:4.00~git30-7274cfa-1.1) ...\n",
            "Collecting hunspell\n",
            "  Downloading hunspell-0.5.5.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hunspell\n",
            "  Building wheel for hunspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hunspell: filename=hunspell-0.5.5-cp312-cp312-linux_x86_64.whl size=66944 sha256=f667d371e69a9d8354df2f911042d55178283bcb298552cc329afa5a5de308c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/1e/1c/3438c8e5af66b88b3bab7d99b7c2ec24a9bfe669b57c3f87a6\n",
            "Successfully built hunspell\n",
            "Installing collected packages: hunspell\n",
            "Successfully installed hunspell-0.5.5\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyluach\n",
        "!pip install transformers\n",
        "!sudo apt-get install libhunspell-dev\n",
        "!pip install pyspellchecker\n",
        "!pip install torch torchvision\n",
        "!pip install opencv-python\n",
        "!pip install pytesseract\n",
        "!apt-get install tesseract-ocr tesseract-ocr-heb\n",
        "!pip install hunspell\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "import hunspell\n",
        "from spellchecker import SpellChecker\n",
        "from pyluach.dates import GregorianDate, HebrewDate\n",
        "import torch\n",
        "import cv2\n",
        "from contextlib import contextmanager\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "__2sLzQopJOh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "8351484549f643dc8c0d8d91a7499913",
            "ed176921933c43dcbc7fcb9fb5d8901c",
            "2fda62722f1b4510b2cea75ffe2ce114",
            "a65d95e6435349d8892b189346768d5d",
            "1634b4b016aa4dabada18f2a364e95ad",
            "c05f94f1ad0545dc8eee560fda5413ff",
            "7a85ee82f8fc4732848c5bf7a751847e",
            "d47198aecb9347cd9e7824057a1f3372",
            "c237576e479e48a897262fbdc6c88c6a",
            "9f5bc4d882254f859bd1476308f7f8f3",
            "a9eb859ccf7c423894dfa07bb6cc540e",
            "29cac26a4b59434eb8fd5034a12702e6",
            "0a71a013d0754ff588359b343c36f88f",
            "4c658c16b3ff4af49e3270bac5c417e8",
            "c518f231023044e9a6e221e73c6487cd",
            "f37a109a69e54a02b2c11a122f373cca",
            "65208dd07b1d4d75b0724f28404827c5",
            "ae637646f5a54f3a852efbdaa13fc000",
            "fe0e578959424355b81ed076489e20af",
            "8cc80f9c10fc4006a587f119d66df5a5"
          ]
        },
        "id": "ntYXwP8gpRVn",
        "outputId": "75ceac47-8adc-4547-dbd4-ba32fbeafb63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8351484549f643dc8c0d8d91a7499913"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "662b6d80-1851-4874-8e72-29a6a1c11725"
      },
      "source": [
        "# Configuration\n",
        "BATCH_SIZE = 25\n",
        "MAX_TEXT_LENGTH = 1024\n",
        "\n",
        "# Paths\n",
        "MULTI_AD_INPUT = \"/content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/multi_ads\"\n",
        "SINGLE_AD_INPUT = \"/content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/single_ads\"\n",
        "OUTPUT_CSV = \"/content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/ads_features.csv\"\n",
        "BATCH_OUTPUT_DIR = \"/content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results\"\n",
        "PROGRESS_FILE = \"/content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/progress.txt\"\n",
        "\n",
        "os.makedirs(BATCH_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Hebrew dictionary paths\n",
        "HEBREW_DIC = \"/content/drive/MyDrive/Miki_class/Project/Catalog/he_IL.dic\"\n",
        "HEBREW_AFF = \"/content/drive/MyDrive/Miki_class/Project/Catalog/he_IL.aff\"\n",
        "\n",
        "# Issue dates mapping\n",
        "ISSUE_TO_DATE = {\n",
        "    '1193': '2024-11-03', '1194': '2024-11-10', '1196': '2024-11-24',\n",
        "    '1197': '2024-12-01', '1198': '2024-12-08', '1199': '2024-12-15',\n",
        "    '1200': '2024-12-22', '1201': '2024-12-29', '1202': '2025-01-05',\n",
        "    '1203': '2025-01-12', '1204': '2025-01-19', '1205': '2025-01-26',\n",
        "    '1206': '2025-02-02', '1216': '2025-04-27', '1217': '2025-05-04',\n",
        "    '1218': '2025-05-11', '1219': '2025-05-18', '1220': '2025-05-26',\n",
        "    '1221': '2025-06-01', '1222': '2025-06-08', '1223': '2025-06-15',\n",
        "    '1224': '2025-06-22', '1225': '2025-06-29', '1226': '2025-07-06',\n",
        "    '1227': '2025-07-13', '1228': '2025-07-20', '1229': '2025-07-27',\n",
        "    '1230': '2025-08-04', '1231': '2025-08-10'\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_memory_usage():\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "        return f\"GPU: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved\"\n",
        "    return \"CPU mode\"\n",
        "\n",
        "def aggressive_cleanup():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "def save_progress(batch_num, total_batches, completed_files):\n",
        "    try:\n",
        "        with open(PROGRESS_FILE, 'w') as f:\n",
        "            f.write(f\"Batch {batch_num}/{total_batches}\\n\")\n",
        "            f.write(f\"Files completed: {len(completed_files)}\\n\")\n",
        "            f.write(\"Completed files:\\n\")\n",
        "            for filename in completed_files:\n",
        "                f.write(f\"{filename}\\n\")\n",
        "        print(f\"Progress saved: Batch {batch_num}/{total_batches}, {len(completed_files)} files completed\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving progress: {e}\")\n",
        "\n",
        "def load_progress():\n",
        "    if not os.path.exists(PROGRESS_FILE):\n",
        "        return set()\n",
        "\n",
        "    try:\n",
        "        completed_files = set()\n",
        "        with open(PROGRESS_FILE, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if len(lines) > 3:\n",
        "                for line in lines[3:]:\n",
        "                    filename = line.strip()\n",
        "                    if filename:\n",
        "                        completed_files.add(filename)\n",
        "        print(f\"Progress loaded: {len(completed_files)} files already completed\")\n",
        "        return completed_files\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading progress: {e}\")\n",
        "        return set()"
      ],
      "metadata": {
        "id": "hFKKaLlIpTtp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e652c27-826b-4b38-94e1-6691204617c2"
      },
      "source": [
        "@contextmanager\n",
        "def single_model_context(model_name):\n",
        "    print(f\"Loading {model_name}...\")\n",
        "    model = None\n",
        "\n",
        "    try:\n",
        "        if model_name == \"hebrew_bert\":\n",
        "            from transformers import AutoTokenizer, AutoModel\n",
        "            tokenizer = AutoTokenizer.from_pretrained(\"onlplab/alephbert-base\")\n",
        "            model_obj = AutoModel.from_pretrained(\"onlplab/alephbert-base\")\n",
        "            model = {'tokenizer': tokenizer, 'model': model_obj}\n",
        "            print(\"Hebrew BERT loaded\")\n",
        "\n",
        "        elif model_name == \"hebrew_sentiment\":\n",
        "            from transformers import pipeline\n",
        "            model = pipeline(\n",
        "                \"sentiment-analysis\",\n",
        "                model=\"avichr/heBERT_sentiment_analysis\",\n",
        "                tokenizer=\"avichr/heBERT_sentiment_analysis\"\n",
        "            )\n",
        "            print(\"Hebrew sentiment loaded\")\n",
        "\n",
        "        elif model_name == \"hebrew_ner\":\n",
        "            from transformers import pipeline\n",
        "            model = pipeline(\n",
        "                \"token-classification\",\n",
        "                model=\"avichr/heBERT_NER\",\n",
        "                tokenizer=\"avichr/heBERT_NER\"\n",
        "            )\n",
        "            print(\"Hebrew NER loaded\")\n",
        "\n",
        "        elif model_name == \"object_detection\":\n",
        "            from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "            processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "            model_obj = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "            model = {'processor': processor, 'model': model_obj}\n",
        "            print(\"Object detection loaded\")\n",
        "\n",
        "        elif model_name == \"image_captioning\":\n",
        "            from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "            processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "            model_obj = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "            model = {'processor': processor, 'model': model_obj}\n",
        "            print(\"Image captioning loaded\")\n",
        "\n",
        "        elif model_name == \"vqa\":\n",
        "            from transformers import pipeline\n",
        "            model = pipeline(\"visual-question-answering\")\n",
        "            print(\"VQA loaded\")\n",
        "\n",
        "        yield model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {model_name}: {e}\")\n",
        "        yield None\n",
        "\n",
        "    finally:\n",
        "        print(f\"Cleaning up {model_name}...\")\n",
        "        if model:\n",
        "            if isinstance(model, dict):\n",
        "                for key, value in model.items():\n",
        "                    if hasattr(value, 'to'):\n",
        "                        value.to('cpu')\n",
        "                    del value\n",
        "            else:\n",
        "                if hasattr(model, 'to'):\n",
        "                    model.to('cpu')\n",
        "                del model\n",
        "        model = None\n",
        "        aggressive_cleanup()\n",
        "        print(f\"{model_name} cleaned up\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    h = hunspell.HunSpell(HEBREW_DIC, HEBREW_AFF)\n",
        "    use_hunspell = True\n",
        "    print(\"Hebrew hunspell initialized\")\n",
        "except Exception as e:\n",
        "    print(f\"Hunspell failed: {e}\")\n",
        "    use_hunspell = False\n",
        "\n",
        "spell_en = SpellChecker()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLOa-YUppfUn",
        "outputId": "852ef099-db7f-457a-8434-9d808658d2f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hunspell failed: (2, 'No such file or directory')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44977936-34c7-498a-92c7-57ac62b763f9"
      },
      "source": [
        "similar_chars = [('כ', 'ב'), ('ה', 'ח'), ('ו', 'ן'), ('י', 'ו'), ('ר', 'ד'), ('מ', 'ס')]\n",
        "valid_words = ['בסייעתא', 'השמים', 'בסד']\n",
        "\n",
        "def try_swap(word):\n",
        "    if not use_hunspell:\n",
        "        return word\n",
        "    for char1, char2 in similar_chars:\n",
        "        if char1 in word:\n",
        "            if h.spell(word.replace(char1, char2)):\n",
        "                return word.replace(char1, char2)\n",
        "        if char2 in word:\n",
        "            if h.spell(word.replace(char2, char1)):\n",
        "                return word.replace(char2, char1)\n",
        "    return word\n",
        "\n",
        "def clean_text_heb(text):\n",
        "    try:\n",
        "        if text is np.nan or len(text) == 0:\n",
        "            return \"\"\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'[^א-ת\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    words = text.split()\n",
        "    words = [word for word in words if len(word) > 1]\n",
        "\n",
        "    if not use_hunspell:\n",
        "        return \" \".join(words)\n",
        "\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if not h.spell(word) and word not in valid_words:\n",
        "            word = try_swap(word)\n",
        "            if not h.spell(word):\n",
        "                suggestions = h.suggest(word)\n",
        "                if suggestions:\n",
        "                    new_words.append(suggestions[0])\n",
        "            else:\n",
        "                new_words.append(word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "\n",
        "    new_words = [word for word in new_words if len(new_words) > 1]\n",
        "    return \" \".join(new_words)\n",
        "\n",
        "def clean_text_eng(text):\n",
        "    try:\n",
        "        if text is np.nan or len(text) == 0:\n",
        "            return \"\"\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    words = text.split()\n",
        "    words = [word.lower() for word in words if len(word) > 1 or word == 'I']\n",
        "    words = [word for word in words if word.lower() in spell_en]\n",
        "\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.lower() not in spell_en and spell_en.candidates(word) is not None:\n",
        "            suggestions = spell_en.candidates(word)\n",
        "            new_words.append(next(iter(suggestions)))\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "\n",
        "    return \" \".join(new_words)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2215583-817c-4821-a030-a9561005f63f"
      },
      "source": [
        "category_keywords = {\n",
        "    'religious_services': [\n",
        "        'רב', 'מורה', 'סופר סת\"ם', 'כשרות', 'שחיטה', 'מקווה', 'בית כנסת',\n",
        "        'תלמוד תורה', 'ישיבה', 'כולל', 'בד\"ץ', 'הכשר', 'שמירת שבת',\n",
        "        'תפילין', 'מזוזות', 'ספר תורה', 'קידוש', 'הבדלה', 'רבנות'\n",
        "    ],\n",
        "    'lifecycle_events': [\n",
        "        'ברית', 'בר מצווה', 'בת מצווה', 'חתונה', 'שידוך', 'איירוסין',\n",
        "        'שבע ברכות', 'אבל', 'שבעה', 'שלושים', 'יאהרצייט', 'אזכרה',\n",
        "        'פדיון הבן', 'חלקה', 'קבורה', 'בית עלמין', 'לווייה'\n",
        "    ],\n",
        "    'education': [\n",
        "        'תלמוד תורה', 'ישיבה', 'בית יעקב', 'חינוך', 'מורה', 'מורת',\n",
        "        'גננת', 'גן ילדים', 'לימודים', 'מלמד', 'רבנית', 'חדר'\n",
        "    ],\n",
        "    'children_babies': [\n",
        "        'תינוק', 'תינוקת', 'עגלה', 'חיתול', 'צעצוע', 'מוצץ', 'לידה'\n",
        "    ],\n",
        "    'kosher_food': [\n",
        "        'כשר', 'חלבי', 'בשרי', 'פרווה', 'מהדרין', 'בד\"ץ', 'הכשר'\n",
        "    ],\n",
        "    'women_services': [\n",
        "        'שמלות', 'בגדי נשים', 'פאות', 'כיסוי ראש', 'מיילדת'\n",
        "    ],\n",
        "    'men_services': [\n",
        "        'חליפות', 'טלית', 'תפילין', 'כיפות', 'ארבע כנפות'\n",
        "    ],\n",
        "    'household': [\n",
        "        'רהיטים', 'מטבח', 'ניקיון', 'כביסה', 'מקרר', 'תנור'\n",
        "    ],\n",
        "    'health_medical': [\n",
        "        'רופא', 'רופאה', 'רוקח', 'מרפאה', 'בית חולים', 'ביטוח בריאות'\n",
        "    ],\n",
        "    'real_estate': [\n",
        "        'דירה', 'דירות', 'השכרה', 'מכירה', 'נדלן', 'בית'\n",
        "    ],\n",
        "    'employment': [\n",
        "        'דרושים', 'דרושות', 'משרה', 'עבודה', 'פרנסה'\n",
        "    ]\n",
        "}\n",
        "\n",
        "gender_terms = {\n",
        "    'female': [\n",
        "        'נשים', 'אישה', 'בת', 'אמא', 'בנות', 'כלה', 'יולדת',\n",
        "        'מורת', 'רופאת', 'אחות', 'גננת', 'מיילדת', 'נערה'\n",
        "    ],\n",
        "    'male': [\n",
        "        'גברים', 'איש', 'בן', 'אבא', 'בנים', 'חתן', 'בחור',\n",
        "        'מורה', 'רופא', 'אח', 'מלמד', 'רב', 'נער'\n",
        "    ]\n",
        "}\n",
        "\n",
        "def detect_gender(text_heb, text_eng):\n",
        "    if not text_heb and not text_eng:\n",
        "        return 'neutral'\n",
        "\n",
        "    text = (text_heb or '') + ' ' + (text_eng or '')\n",
        "    text = text.lower()\n",
        "\n",
        "    female_count = sum(1 for term in gender_terms['female'] if term in text)\n",
        "    male_count = sum(1 for term in gender_terms['male'] if term in text)\n",
        "\n",
        "    if female_count > male_count and female_count > 0:\n",
        "        return 'female'\n",
        "    elif male_count > female_count and male_count > 0:\n",
        "        return 'male'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "def detect_category(text_heb, text_eng):\n",
        "    text = (text_heb or '') + ' ' + (text_eng or '')\n",
        "    text = text.lower()\n",
        "\n",
        "    category_scores = {}\n",
        "    for category, keywords in category_keywords.items():\n",
        "        score = sum(1 for keyword in keywords if keyword in text)\n",
        "        category_scores[category] = score\n",
        "\n",
        "    if max(category_scores.values()) > 0:\n",
        "        return max(category_scores, key=category_scores.get)\n",
        "    else:\n",
        "        return 'other'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "905a1778-060a-4c85-a370-3577222677a0"
      },
      "source": [
        "def get_bert_embeddings(text, model_dict):\n",
        "    try:\n",
        "        if not text or pd.isna(text) or not model_dict:\n",
        "            return None\n",
        "\n",
        "        text = text[:MAX_TEXT_LENGTH]\n",
        "        tokenizer = model_dict['tokenizer']\n",
        "        model = model_dict['model']\n",
        "\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=MAX_TEXT_LENGTH)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "        return embeddings.cpu().numpy().tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"BERT embedding error: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_sentiment_advanced(text, sentiment_pipeline):\n",
        "    try:\n",
        "        if not text or pd.isna(text) or not sentiment_pipeline:\n",
        "            return 'neutral'\n",
        "\n",
        "        text = text[:MAX_TEXT_LENGTH]\n",
        "        result = sentiment_pipeline(text)\n",
        "\n",
        "        if isinstance(result, list) and len(result) > 0:\n",
        "            return result[0]['label'].lower()\n",
        "        return 'neutral'\n",
        "    except Exception as e:\n",
        "        print(f\"Sentiment error: {e}\")\n",
        "        return 'neutral'\n",
        "\n",
        "def get_ner_entities(text, ner_pipeline):\n",
        "    try:\n",
        "        if not text or pd.isna(text) or not ner_pipeline:\n",
        "            return []\n",
        "\n",
        "        text = text[:MAX_TEXT_LENGTH]\n",
        "        entities = ner_pipeline(text)\n",
        "\n",
        "        processed_entities = []\n",
        "        current_entity = \"\"\n",
        "        current_type = \"\"\n",
        "\n",
        "        for entity in entities:\n",
        "            word = entity['word']\n",
        "            entity_type = entity['entity']\n",
        "\n",
        "            if word.startswith('##'):\n",
        "                current_entity += word[2:]\n",
        "            else:\n",
        "                if current_entity and len(current_entity) > 2:\n",
        "                    processed_entities.append({\n",
        "                        'entity': current_entity,\n",
        "                        'type': current_type,\n",
        "                        'score': entity['score']\n",
        "                    })\n",
        "\n",
        "                current_entity = word\n",
        "                current_type = entity_type\n",
        "\n",
        "        if current_entity and len(current_entity) > 2:\n",
        "            processed_entities.append({\n",
        "                'entity': current_entity,\n",
        "                'type': current_type,\n",
        "                'score': entity.get('score', 0)\n",
        "            })\n",
        "\n",
        "\n",
        "        return processed_entities\n",
        "    except Exception as e:\n",
        "        print(f\"NER error: {e}\")\n",
        "        return []"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COCO_CLASSES = ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "                'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
        "                'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
        "                'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',\n",
        "                'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "                'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
        "                'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "                'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
        "                'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "                'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\n",
        "                'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',\n",
        "                'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
        "                'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
      ],
      "metadata": {
        "id": "U1Om84PGrc0e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b29949a-e56f-456b-b16c-b05393326117"
      },
      "source": [
        "def extract_dominant_colors(image, num_colors=5):\n",
        "    try:\n",
        "        image = image.resize((100, 100))\n",
        "        image_data = np.array(image)\n",
        "        image_data = image_data.reshape((-1, 3))\n",
        "        kmeans = KMeans(n_clusters=num_colors, random_state=42, n_init=10)\n",
        "        kmeans.fit(image_data)\n",
        "        colors = kmeans.cluster_centers_.astype(int)\n",
        "        return [tuple(color) for color in colors]\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def check_if_greyscale(image):\n",
        "    try:\n",
        "        image_data = np.array(image)\n",
        "        if len(image_data.shape) < 3:\n",
        "            return True\n",
        "        return np.all(image_data[:, :, 0] == image_data[:, :, 1]) and np.all(image_data[:, :, 1] == image_data[:, :, 2])\n",
        "    except:\n",
        "        return False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(image, model_dict):\n",
        "    try:\n",
        "        if not model_dict:\n",
        "            return []\n",
        "\n",
        "        processor = model_dict['processor']\n",
        "        model = model_dict['model']\n",
        "\n",
        "        inputs = processor(images=image, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        target_sizes = torch.tensor([image.size[::-1]])\n",
        "        results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.5)[0]\n",
        "\n",
        "        detected_objects = []\n",
        "        for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "            if label.item() < len(COCO_CLASSES):\n",
        "                label_name = COCO_CLASSES[label.item()]\n",
        "                detected_objects.append(label_name)\n",
        "\n",
        "        return list(set(detected_objects))\n",
        "    except Exception as e:\n",
        "        print(f\"Object detection error: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "CIrv6Ea_puUd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_text_caption(image, model_dict):\n",
        "    try:\n",
        "        if not model_dict:\n",
        "            return \"\"\n",
        "\n",
        "        processor = model_dict['processor']\n",
        "        model = model_dict['model']\n",
        "\n",
        "        inputs = processor(image, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            out = model.generate(**inputs)\n",
        "        return processor.decode(out[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Image captioning error: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "hRBxI-52psk5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_religious_vqa(image, vqa_pipeline):\n",
        "    try:\n",
        "        if not vqa_pipeline:\n",
        "            return False\n",
        "\n",
        "        question = \"Are there any religious symbols or Jewish content in this image?\"\n",
        "        result = vqa_pipeline(image, question)\n",
        "        answer = result['answer'] if isinstance(result, dict) else result[0]['answer']\n",
        "        return 'yes' in str(answer).lower() or 'religious' in str(answer).lower()\n",
        "    except Exception as e:\n",
        "        print(f\"VQA error: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "QL82X88gpqwU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86683e02-0f2f-430a-a7c1-e30a85b10348"
      },
      "source": [
        "def extract_comprehensive_prices(text_heb, text_eng):\n",
        "    all_text = (text_heb or '') + ' ' + (text_eng or '')\n",
        "    if not all_text:\n",
        "        return []\n",
        "\n",
        "    patterns = [\n",
        "        r'₪\\s*(\\d{1,6}(?:\\.\\d{1,2})?)',\n",
        "        r'(\\d{1,6}(?:\\.\\d{1,2})?)\\s*₪',\n",
        "        r'ש\"ח\\s*(\\d{1,6}(?:\\.\\d{1,2})?)',\n",
        "        r'(\\d{1,6}(?:\\.\\d{1,2})?)\\s*ש\"ח',\n",
        "        r'מחיר\\s*(\\d{1,6}(?:\\.\\d{1,2})?)',\n",
        "        r'רק\\s*(\\d{1,6}(?:\\.\\d{1,2})?)',\n",
        "        r'(\\d{1,6}(?:\\.\\d{1,2})?)',\n",
        "        r'(\\d+)\\s*אלף',\n",
        "    ]\n",
        "\n",
        "    prices = []\n",
        "    for pattern in patterns:\n",
        "        matches = re.findall(pattern, all_text)\n",
        "        for match in matches:\n",
        "            try:\n",
        "                if 'אלף' in pattern:\n",
        "                    price_val = float(match) * 1000\n",
        "                else:\n",
        "                    price_val = float(match)\n",
        "\n",
        "                if 0.1 <= price_val <= 1000000:\n",
        "                    prices.append(price_val)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    return sorted(list(set(prices)))\n",
        "\n",
        "def check_holiday_proximity(date_str):\n",
        "    if not date_str:\n",
        "        return {\n",
        "            'is_near_holiday': False,\n",
        "            'nearby_holidays': [],\n",
        "            'days_to_holiday': None,\n",
        "            'is_pre_holiday': False,\n",
        "            'is_post_holiday': False\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        base_date = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "        nearby_holidays = []\n",
        "        min_days_to_holiday = float('inf')\n",
        "\n",
        "        for days_offset in range(-7, 8):\n",
        "            check_date = base_date + timedelta(days=days_offset)\n",
        "            gregorian_date = GregorianDate(check_date.year, check_date.month, check_date.day)\n",
        "\n",
        "            try:\n",
        "                holiday = gregorian_date.holiday()\n",
        "                if holiday:\n",
        "                    nearby_holidays.append({\n",
        "                        'holiday': holiday,\n",
        "                        'date': check_date.strftime('%Y-%m-%d'),\n",
        "                        'days_offset': days_offset\n",
        "                    })\n",
        "                    if abs(days_offset) < abs(min_days_to_holiday):\n",
        "                        min_days_to_holiday = days_offset\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return {\n",
        "            'is_near_holiday': len(nearby_holidays) > 0,\n",
        "            'nearby_holidays': str(nearby_holidays),\n",
        "            'days_to_holiday': min_days_to_holiday if min_days_to_holiday != float('inf') else None,\n",
        "            'is_pre_holiday': min_days_to_holiday > 0 if min_days_to_holiday != float('inf') else False,\n",
        "            'is_post_holiday': min_days_to_holiday < 0 if min_days_to_holiday != float('inf') else False\n",
        "        }\n",
        "    except:\n",
        "        return {\n",
        "            'is_near_holiday': False,\n",
        "            'nearby_holidays': [],\n",
        "            'days_to_holiday': None,\n",
        "            'is_pre_holiday': False,\n",
        "            'is_post_holiday': False\n",
        "        }\n",
        "\n",
        "\n",
        "def check_shabbat_timing(date_str):\n",
        "    if not date_str:\n",
        "        return {'is_pre_shabbat': False, 'weekday': None}\n",
        "\n",
        "    try:\n",
        "        date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "        weekday = date_obj.weekday()\n",
        "        return {\n",
        "            'is_pre_shabbat': weekday in [3, 4],\n",
        "            'weekday': date_obj.strftime('%A')\n",
        "        }\n",
        "    except:\n",
        "        return {'is_pre_shabbat': False, 'weekday': None}\n",
        "\n",
        "def detect_shabbat_content(text):\n",
        "    if not text:\n",
        "        return {'has_shabbat_terms': False, 'shabbat_term_count': 0}\n",
        "\n",
        "    shabbat_terms = ['שבת', 'שבתות', 'מוצש', 'מוצאי שבת', 'הדלקת נרות', 'קידוש', 'הבדלה']\n",
        "    text_lower = text.lower()\n",
        "    found_terms = [term for term in shabbat_terms if term in text_lower]\n",
        "\n",
        "    return {\n",
        "        'has_shabbat_terms': len(found_terms) > 0,\n",
        "        'shabbat_term_count': len(found_terms)\n",
        "    }"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30b77b8e-26ac-4772-a50e-b218983a75f3"
      },
      "source": [
        "def process_basic_features(image_path, filename, ad_type):\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        text_heb = pytesseract.image_to_string(image, lang=\"heb\")\n",
        "        text_eng = pytesseract.image_to_string(image, lang=\"eng\")\n",
        "\n",
        "        text_heb_clean = clean_text_heb(text_heb)\n",
        "        text_eng_clean = clean_text_eng(text_eng)\n",
        "\n",
        "        width, height = image.size\n",
        "        colors = extract_dominant_colors(image)\n",
        "        is_greyscale = check_if_greyscale(image)\n",
        "\n",
        "        gender = detect_gender(text_heb_clean, text_eng_clean)\n",
        "        category = detect_category(text_heb_clean, text_eng_clean)\n",
        "        prices = extract_comprehensive_prices(text_heb_clean, text_eng_clean)\n",
        "\n",
        "        if ad_type == 'multi' and '_' in filename:\n",
        "            parts = filename.split('_')\n",
        "            issue = parts[1] if len(parts) > 1 else 'unknown'\n",
        "        else:\n",
        "            issue = 'single'\n",
        "\n",
        "        issue_date = ISSUE_TO_DATE.get(issue)\n",
        "        holiday_info = check_holiday_proximity(issue_date)\n",
        "        shabbat_timing = check_shabbat_timing(issue_date)\n",
        "        shabbat_content = detect_shabbat_content(text_heb_clean)\n",
        "\n",
        "        has_discount = any(term in (text_heb_clean + ' ' + text_eng_clean).lower()\n",
        "                          for term in ['הנחה', 'מבצע', 'סייל', 'זול', 'הזדמנות'])\n",
        "\n",
        "\n",
        "        return {\n",
        "            'filename': filename,\n",
        "            'ad_type': ad_type,\n",
        "            'issue': issue,\n",
        "            'issue_date': issue_date,\n",
        "            'image_path': image_path,\n",
        "            'width': width,\n",
        "            'height': height,\n",
        "            'aspect_ratio': width / height if height > 0 else 0,\n",
        "            'is_greyscale': is_greyscale,\n",
        "            'text_heb_raw': text_heb,\n",
        "            'text_eng_raw': text_eng,\n",
        "            'text_heb_clean': text_heb_clean,\n",
        "            'text_eng_clean': text_eng_clean,\n",
        "            'text_heb_length': len(text_heb_clean.split()) if text_heb_clean else 0,\n",
        "            'text_eng_length': len(text_eng_clean.split()) if text_eng_clean else 0,\n",
        "            'main_colors': colors,\n",
        "            'total_colors': len(set(colors)) if colors else 0,\n",
        "            'gender_target': gender,\n",
        "            'product_category': category,\n",
        "            'prices': prices,\n",
        "            'min_price': min(prices) if prices else None,\n",
        "            'max_price': max(prices) if prices else None,\n",
        "            'avg_price': sum(prices)/len(prices) if prices else None,\n",
        "            'price_count': len(prices),\n",
        "            'has_discount': has_discount,\n",
        "            'is_near_holiday': holiday_info['is_near_holiday'],\n",
        "            'nearby_holidays': holiday_info['nearby_holidays'],\n",
        "            'days_to_holiday': holiday_info['days_to_holiday'],\n",
        "            'is_pre_holiday': holiday_info['is_pre_holiday'],\n",
        "            'is_post_holiday': holiday_info['is_post_holiday'],\n",
        "            'weekday': shabbat_timing['weekday'],\n",
        "            'is_pre_shabbat': shabbat_timing['is_pre_shabbat'],\n",
        "            'has_shabbat_terms': shabbat_content['has_shabbat_terms'],\n",
        "            'shabbat_term_count': shabbat_content['shabbat_term_count'],\n",
        "            'text_embeddings': None,\n",
        "            'sentiment_advanced': 'neutral',\n",
        "            'ner_entities': [],\n",
        "            'person_entities': 0,\n",
        "            'location_entities': 0,\n",
        "            'organization_entities': 0,\n",
        "            'detected_objects': [],\n",
        "            'object_count': 0,\n",
        "            'has_people': False,\n",
        "            'has_food': False,\n",
        "            'has_furniture': False,\n",
        "            'has_electronics': False,\n",
        "            'image_caption': \"\",\n",
        "            'is_religious_visual': False\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {filename}: {e}\")\n",
        "        return None"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e66b7383-c70c-4cd9-83b7-9622b1f1435b"
      },
      "source": [
        "def process_batch_with_individual_models(batch_df):\n",
        "    print(f\"Processing batch of {len(batch_df)} images\")\n",
        "    print(f\"Memory before processing: {get_memory_usage()}\")\n",
        "\n",
        "    # Phase 1: Hebrew BERT Embeddings\n",
        "    print(\"Phase 1: BERT Embeddings\")\n",
        "    with single_model_context(\"hebrew_bert\") as bert_model:\n",
        "        if bert_model:\n",
        "            batch_df['text_embeddings'] = batch_df['text_heb_clean'].apply(\n",
        "                lambda x: get_bert_embeddings(x, bert_model)\n",
        "            )\n",
        "        print(f\"Memory after BERT: {get_memory_usage()}\")\n",
        "\n",
        "    # Phase 2: Hebrew Sentiment Analysis\n",
        "    print(\"Phase 2: Sentiment Analysis\")\n",
        "    with single_model_context(\"hebrew_sentiment\") as sentiment_model:\n",
        "        if sentiment_model:\n",
        "            batch_df['sentiment_advanced'] = batch_df['text_heb_clean'].apply(\n",
        "                lambda x: get_sentiment_advanced(x, sentiment_model)\n",
        "            )\n",
        "        print(f\"Memory after Sentiment: {get_memory_usage()}\")\n",
        "\n",
        "    # Phase 3: Named Entity Recognition\n",
        "    print(\"Phase 3: Named Entity Recognition\")\n",
        "    with single_model_context(\"hebrew_ner\") as ner_model:\n",
        "        if ner_model:\n",
        "            batch_df['ner_entities'] = batch_df['text_heb_clean'].apply(\n",
        "                lambda x: get_ner_entities(x, ner_model)\n",
        "            )\n",
        "\n",
        "            batch_df['person_entities'] = batch_df['ner_entities'].apply(\n",
        "                lambda x: len([e for e in x if 'PER' in e.get('type', '')])\n",
        "            )\n",
        "            batch_df['location_entities'] = batch_df['ner_entities'].apply(\n",
        "                lambda x: len([e for e in x if 'LOC' in e.get('type', '')])\n",
        "            )\n",
        "            batch_df['organization_entities'] = batch_df['ner_entities'].apply(\n",
        "                lambda x: len([e for e in x if 'ORG' in e.get('type', '')])\n",
        "            )\n",
        "        print(f\"Memory after NER: {get_memory_usage()}\")\n",
        "\n",
        "    # Phase 4: Object Detection\n",
        "    print(\"Phase 4: Object Detection\")\n",
        "    with single_model_context(\"object_detection\") as obj_model:\n",
        "        if obj_model:\n",
        "            for idx, row in batch_df.iterrows():\n",
        "                try:\n",
        "                    image = Image.open(row['image_path']).convert(\"RGB\")\n",
        "                    detected_objects = detect_objects(image, obj_model)\n",
        "\n",
        "                    batch_df.at[idx, 'detected_objects'] = detected_objects\n",
        "                    batch_df.at[idx, 'object_count'] = len(detected_objects)\n",
        "                    batch_df.at[idx, 'has_people'] = 'person' in detected_objects\n",
        "                    batch_df.at[idx, 'has_food'] = any(obj in detected_objects for obj in ['apple', 'banana', 'cake', 'pizza', 'sandwich'])\n",
        "                    batch_df.at[idx, 'has_furniture'] = any(obj in detected_objects for obj in ['chair', 'dining table', 'couch', 'bed'])\n",
        "                    batch_df.at[idx, 'has_electronics'] = any(obj in detected_objects for obj in ['tv', 'laptop', 'cell phone', 'remote'])\n",
        "                except Exception as e:\n",
        "                    print(f\"Object detection error for {row['filename']}: {e}\")\n",
        "        print(f\"Memory after Object Detection: {get_memory_usage()}\")\n",
        "\n",
        "    # Phase 5: Image Captioning\n",
        "    print(\"Phase 5: Image Captioning\")\n",
        "    with single_model_context(\"image_captioning\") as caption_model:\n",
        "        if caption_model:\n",
        "            for idx, row in batch_df.iterrows():\n",
        "                try:\n",
        "                    image = Image.open(row['image_path']).convert(\"RGB\")\n",
        "                    caption = image_to_text_caption(image, caption_model)\n",
        "                    batch_df.at[idx, 'image_caption'] = caption\n",
        "                except Exception as e:\n",
        "                    print(f\"Image captioning error for {row['filename']}: {e}\")\n",
        "        print(f\"Memory after Image Captioning: {get_memory_usage()}\")\n",
        "\n",
        "    # Phase 6: Visual Question Answering\n",
        "    print(\"Phase 6: Visual Question Answering\")\n",
        "    with single_model_context(\"vqa\") as vqa_model:\n",
        "        if vqa_model:\n",
        "            for idx, row in batch_df.iterrows():\n",
        "                try:\n",
        "                    image = Image.open(row['image_path']).convert(\"RGB\")\n",
        "                    is_religious = is_religious_vqa(image, vqa_model)\n",
        "                    batch_df.at[idx, 'is_religious_visual'] = is_religious\n",
        "                except Exception as e:\n",
        "                    print(f\"VQA error for {row['filename']}: {e}\")\n",
        "        print(f\"Memory after VQA: {get_memory_usage()}\")\n",
        "\n",
        "    print(f\"Batch processing complete. Final memory: {get_memory_usage()}\")\n",
        "    return batch_df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2f981f2-d997-4079-8764-797f738f066d"
      },
      "source": [
        "def get_image_files():\n",
        "    all_files = []\n",
        "\n",
        "    if os.path.exists(MULTI_AD_INPUT):\n",
        "        multi_files = [f for f in os.listdir(MULTI_AD_INPUT) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        all_files.extend([(os.path.join(MULTI_AD_INPUT, f), f, 'multi') for f in multi_files])\n",
        "        print(f\"Found {len(multi_files)} multi-ad files\")\n",
        "    else:\n",
        "        print(f\"Multi-ad directory not found: {MULTI_AD_INPUT}\")\n",
        "\n",
        "    if os.path.exists(SINGLE_AD_INPUT):\n",
        "        single_files = [f for f in os.listdir(SINGLE_AD_INPUT) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        all_files.extend([(os.path.join(SINGLE_AD_INPUT, f), f, 'single') for f in single_files])\n",
        "        print(f\"Found {len(single_files)} single-ad files\")\n",
        "    else:\n",
        "        print(f\"Single-ad directory not found: {SINGLE_AD_INPUT}\")\n",
        "\n",
        "    return all_files\n",
        "\n",
        "def save_batch_results(batch_df, batch_num):\n",
        "    batch_file = os.path.join(BATCH_OUTPUT_DIR, f\"batch_{batch_num:03d}.csv\")\n",
        "    try:\n",
        "        batch_df.to_csv(batch_file, index=False)\n",
        "        print(f\"Batch {batch_num} saved to: {batch_file}\")\n",
        "        return batch_file\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving batch {batch_num}: {e}\")\n",
        "        return None\n",
        "\n",
        "def combine_all_batches():\n",
        "    print(\"Combining all batch files...\")\n",
        "    batch_files = [f for f in os.listdir(BATCH_OUTPUT_DIR) if f.startswith('batch_') and f.endswith('.csv')]\n",
        "    batch_files.sort()\n",
        "\n",
        "    if not batch_files:\n",
        "        print(\"No batch files found to combine\")\n",
        "        return None\n",
        "\n",
        "    all_dfs = []\n",
        "    for batch_file in batch_files:\n",
        "        try:\n",
        "            batch_path = os.path.join(BATCH_OUTPUT_DIR, batch_file)\n",
        "            df = pd.read_csv(batch_path)\n",
        "            all_dfs.append(df)\n",
        "            print(f\"Loaded {batch_file}: {len(df)} records\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {batch_file}: {e}\")\n",
        "\n",
        "    if all_dfs:\n",
        "        combined_df = pd.concat(all_dfs, ignore_index=True)\n",
        "        combined_df.to_csv(OUTPUT_CSV, index=False)\n",
        "        print(f\"Combined dataset saved to: {OUTPUT_CSV}\")\n",
        "        print(f\"Total records: {len(combined_df)}\")\n",
        "        return combined_df\n",
        "\n",
        "    return None\n",
        "\n",
        "def run_processing_pipeline():\n",
        "\n",
        "    all_files = get_image_files()\n",
        "    if not all_files:\n",
        "        print(\"No files found to process\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Total files to process: {len(all_files)}\")\n",
        "\n",
        "    completed_files = load_progress()\n",
        "\n",
        "    remaining_files = [(path, filename, ad_type) for path, filename, ad_type in all_files\n",
        "                      if filename not in completed_files]\n",
        "\n",
        "    if not remaining_files:\n",
        "        print(\"All files already processed. Combining existing batches...\")\n",
        "        return combine_all_batches()\n",
        "\n",
        "    print(f\"Remaining files to process: {len(remaining_files)}\")\n",
        "\n",
        "    total_batches = (len(remaining_files) + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "    print(f\"Will process in {total_batches} batches of {BATCH_SIZE} files each\")\n",
        "\n",
        "    for batch_num in range(1, total_batches + 1):\n",
        "        batch_start = (batch_num - 1) * BATCH_SIZE\n",
        "        batch_end = min(batch_start + BATCH_SIZE, len(remaining_files))\n",
        "        batch_files = remaining_files[batch_start:batch_end]\n",
        "\n",
        "        print(f\"\\n\" + \"=\"*40)\n",
        "        print(f\"PROCESSING BATCH {batch_num}/{total_batches}\")\n",
        "        print(f\"Files {batch_start+1}-{batch_end} of {len(remaining_files)}\")\n",
        "        print(f\"Memory at start: {get_memory_usage()}\")\n",
        "        print(\"=\"*40)\n",
        "\n",
        "        print(\"Phase 1: Basic feature extraction\")\n",
        "        batch_data = []\n",
        "        for image_path, filename, ad_type in tqdm(batch_files, desc=\"Basic processing\"):\n",
        "            result = process_basic_features(image_path, filename, ad_type)\n",
        "            if result:\n",
        "                batch_data.append(result)\n",
        "\n",
        "        if not batch_data:\n",
        "            print(f\"No valid data in batch {batch_num}, skipping\")\n",
        "            continue\n",
        "\n",
        "        batch_df = pd.DataFrame(batch_data)\n",
        "        print(f\"Basic features extracted for {len(batch_df)} files\")\n",
        "\n",
        "        batch_df = process_batch_with_individual_models(batch_df)\n",
        "\n",
        "        batch_file = save_batch_results(batch_df, batch_num)\n",
        "        if batch_file:\n",
        "            print(f\"Batch {batch_num} successfully saved\")\n",
        "\n",
        "        new_completed_files = completed_files.union(set(batch_df['filename'].tolist()))\n",
        "        save_progress(batch_num, total_batches, new_completed_files)\n",
        "        completed_files = new_completed_files\n",
        "\n",
        "\n",
        "        print(f\"Batch {batch_num} complete. Total completed: {len(completed_files)}\")\n",
        "\n",
        "        aggressive_cleanup()\n",
        "        print(f\"Memory after cleanup: {get_memory_usage()}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"All batches processed. Combining results...\")\n",
        "    final_df = combine_all_batches()\n",
        "\n",
        "    if final_df is not None:\n",
        "        print(\"=\"*60)\n",
        "        print(\"PROCESSING COMPLETE\")\n",
        "        print(\"=\"*60)\n",
        "        return final_df\n",
        "    else:\n",
        "        print(\"Error combining batch results\")\n",
        "        return None"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bc525328bc454f88b323c440029de845",
            "44227f922613438f9178f1de3a477e46",
            "66c77e305d4d4337bb0da1dde98707ea",
            "3a20b2d757d24e769ec361462ef40610",
            "48a5553078854425bf9d04bca9f6f998",
            "ee276d94c4b04f2a80ffa40bef84ea5a",
            "5c55ae1ae91340d28de2bd630915bd4c",
            "7c290584c1ce448cb452ed357506fd7d",
            "1581be0b6e094a569da433015fa88380",
            "7519d6fb81eb45869c0261d2f6536aac",
            "bd986d451f17402da08435638dc27476",
            "c00fae74a3784d6ca98794697edc9120",
            "5fb0029c13fa42d2a7811a236a28680e",
            "68fc8484db834e0bade5f53cca48bb54",
            "b050162a801e4368a3612dede2126678",
            "b9ac609d615e4bcbb1c2e1093c559dca",
            "4f17143dc12c447fbf8bc837be34e60d",
            "6990158e65fe402fbe4c7594974a5868",
            "bf9e3269b9cf49e4a5bb1b5ca503da4c",
            "680de0b3d07c4619924df999eaa10196",
            "303231f7e56c4b3fbd4e732c73bc9d3e",
            "5f272e7cdb6247caac8b7657fad05e6b",
            "ffa03d32760748a1b9a60fa5f826bcb1",
            "ecf3c2a96bb9486b8497654fb02cb945",
            "5e55572ec17e4c9aafcfcb4a37d05276",
            "51e9c8e2a21a490aa3b4b82ddd666a6b",
            "85f3134a50364645bb9e855a95793fa0",
            "a6b4451033fd4d3191edd348e069d115",
            "c8def8e6b82f4686aa8691280511cbcc",
            "85bba20409284ef2888b50c5687092bf",
            "875efd7ba144463ea9440762bfc52316",
            "2d9309d4b6024bcaab322da10589b9c9",
            "603f71a4799b4417bbdd02940d05f4a7",
            "5329467d74fd4071a24b064492d17365",
            "842a77ba282d4ad8833aeb9ab3a10403",
            "35f9e97618b14eca8433138cc0ba011d",
            "2188fc1e91e2472f898c596ae79cd8e4",
            "1de2848f29f84acbb464fcd3f80ad39c",
            "142415c5496c4567aeb982db7624e4b2",
            "954275880c53458db0ade5f5733094d1",
            "042177b305914596b25bdf74819ccbdd",
            "6d09e1c841fe4a0cb3b3644f4a5c52e1",
            "850646c348ff45fc9b8a186c2acc551e",
            "77447efb4f0b4d53844c2e676817020f",
            "94cecb7a9f5044ce98dacd85a1507fa8",
            "0e6a95a09e234b1f87284dd1ca61e537",
            "4f1888ab3f664c5a8d0582f022eaaeb6",
            "33f2ae033d5a4c2e8c3de22b8ea6d42e",
            "6e3e161e14f041b9913bb569252e34d8",
            "8df6dd0457b44d0b82473804aa7ce319",
            "35be83ffd1fc47feaac877c0ff6f800f",
            "a48a73f7269b4d268553565923aec3e3",
            "449b3dc89678433690daf76402558375",
            "697651a6bf17469985ce7baca6a527a6",
            "19c90adc72454f00be4366bf613328f1",
            "27db0446f4dd475d8e619d62d8c94582",
            "d29b352ebb5b42598f9d232f8459f0bc",
            "eef6c57c37f647ff9df3a7970c224bfa",
            "6de9e425ac6a4f5a96493f6b5b3b7432",
            "43e6b0fb7d99467aab93361e18d7d463",
            "3b31d970f7d843fcb56cb957400f0ba0",
            "853ce92128d34c91ba466cca5ae36c69",
            "a66ce15787414c95abae030df395cc98",
            "1ab7633239e646c5bafdc7c1655729f7",
            "f514fb6d943c4b7683106346c8b4688f",
            "e715a340fa9f46b6832ffb657025451c",
            "0b6958ae13884be2afe026ceef3cfc79",
            "fde7728bea9a447b9bac02745b0cd390",
            "b12394c010d949e09aaad8700bd0e8d3",
            "f51fc02867bc43a29113dc3653e171ef",
            "00f1782c75544b3cbabb6fa04c715773",
            "55925486fa9f4f8eb7df7ba10f5cf35f",
            "6bf9da2236b440eeb390f156319b06a8",
            "85ccc82ffba24ce58df39cad18dbaf57",
            "725f292bb9204e05a4187628bbd15233",
            "8a84a8875a694fbeb789f1cf6ce71da9",
            "0bb9f52b2d5e4351b3681bccbdbd5003",
            "f060f691b4854ce59d9be912f373e55f",
            "9756424b07264f539fbe3102ea7e2a4c",
            "d0974b2830b84985986de79cd0f94de5",
            "679dec99b47642aba89d9d9f8afe8961",
            "0dee001b7663465fb23447ffb88d2018",
            "afab0042a40745e39986e991fd813c83",
            "c03216a9b9394bd690594ba727acfa20",
            "77331dae1b9c4c2eb30224851dfad917",
            "3fa6bc0bff6b416dbaab4ff549e03fe3",
            "600bf9ec6c23485783618bcd8eb8a55f",
            "95bb8c4929e742f8b693377397ef5475",
            "c05b62f0bba34f35bfbbaedbe2c1618a",
            "706c74483f2c41ae9879ba12bb23bb94",
            "d33b7fab7f9d4b78924d81e0af9c9d5c",
            "7af0a12bb82743f1a3aeb8685fe1cb03",
            "5a3917f9a49a440a858bdf657cdde9a9",
            "0c6d9b88e61b477fa2c01a603656311d",
            "7395647c711644fcabc69c1dde483075",
            "72123257629f4306946075c5a4e58f71",
            "7d2a0d60b97445c794563bcb85c2d1e6",
            "d8bb06ddef384b1986236b5b3ad787c0",
            "1d442ce792514ee28c0fbc50eab602e1",
            "96260f9cd42a4aef92915f8006623098",
            "da4526196cac4511bf4435ed07ed166b",
            "412a3af2adac4bcc99584a76c65dbacd",
            "806dfae1fa514f20b9e2b9941f3d9a0d",
            "424458084c5d474684b96dd55b209461",
            "b81374ab52824fc4b549823a3f372a69",
            "940cd4e47b0f497ab6541c0c82c78232",
            "8f6128e8247c485fa18f0050d6913972",
            "03bf18df713c408682fae96767a20351",
            "5b6dcf4f051d43ba869be26f32ce4f2e",
            "ce24ab00c79248e6bb4264f8507fe805",
            "eef87e9e3483470f861fadd8fc4b4a40",
            "9290e8e50be249bc89e1898c53ba875d",
            "7fea54de032246feaee1577e2b9fa84e",
            "746fe843c5094b9f84df80b56752b7b9",
            "012c9964368345758ca4dd1c8c3f17c7",
            "6f07374bd55443ccbd4a16d15e1b402a",
            "f40ec04b476d40ee86037fc617564f0c",
            "d959254f32624fa981857b3040a48d4d",
            "6b2323650fd249cfa0e787c259574419",
            "6e5151d836604318bb47ab2291406087",
            "9092c2fd3742401d810cb0b4a718e4a6",
            "28adc8e2ad37404aa579aecc8a1b56d8",
            "28504b6b818b467a8f31a04e7cfb914c",
            "dca197c538514b35bb92fa38439bc67b",
            "060f7399c76d47de84eab11f583f2097",
            "eb26a868781342059436039819a16ec0",
            "daeea5a33e32479bbf8ac7124e8a0f63",
            "46969ebc9f994873b1183c0b2dba17ab",
            "dd4e34e8ddf74127b8e26918637f8cd1",
            "db78d132702a4e918c0a12d9fbc139d8",
            "371c85c5022c413f9ffc8adbac0118f3",
            "8eb284fb1a7e4520a929acbb67b8384e",
            "690d945a7e7948e5ae63684a15d0c107",
            "7779a525919d4581a1938d69fbed72b4",
            "9c8a568b0c3e49398d3a86110d70c3f7",
            "a91d313b565a4a7d88886ced8d37ac4d",
            "3fb6497b4feb43e0aa2d19effa992027",
            "ee195ed045594d6094754988b9382356",
            "cd7cfe5b922b4a6d939b799745e6684b",
            "60adf7a6b2de4b79bf5e6aa257516f4a",
            "8eda984b6cdf463585a8ed50ef967d92",
            "d46f66d216554a4189105ed92d62290f",
            "66b3e528c502476db26b7eeda515ee76",
            "c4f001318f0b48d9bf03e8f2f55ce10d",
            "7bfc84f1ee31436cbde89bdd05f082aa",
            "895b6fd27eb2419fb64512967745c02c",
            "5774ad648b9249c8b709c87d688320cf",
            "428e0480daf447dd8ac9bd4575bf5a09",
            "3e1845a6c6c742f2b5f432c34c542074",
            "e2a39d9306494bb38f4110c63228ade6",
            "c628d119d8154d4dba79cd0e5ff12e6c",
            "7c61ef5a2ab340ddbc5a2f1dbcf22ece",
            "b71f0e6e4787414f9f9a228353800923",
            "eacaac1e0e284a78a02066183b548b54",
            "e2c0a1da161b491a82401f3de01786ba",
            "66bdc24e84a640a7a6a645fb2cf6e715",
            "9211ef99eff643eba0664a0a498c1b14",
            "947360425c66485e8049cc0a206eed89",
            "f00796c13e6c47d195100459bd21a1c4",
            "eb2eb47d10844eccbb93f029457dd3aa",
            "11bc56f114e4469fa81e75d449e9b38b",
            "f2706ff571b9487a9f38629ac5832a31",
            "b69605eaac774224b3135c9451018460",
            "9829750590cd421499a5d4b26e5862bb",
            "7a16408fc7a64da4b4a0962c0f3e3933",
            "7b9ae152c60b4a31aa4f0032c453755f",
            "8f003414a3df4562a2baf72ada1ab6c9",
            "3afa2264692c493bbefcb5456232f948",
            "b259348fbb3a41688bcc2f4a20e20282",
            "58d9a0b191c649b3ad2d96178bc1c927",
            "6218ff177486469d9976506fc32aca06",
            "5121e8b2912248cc9b26b52aa64aac91",
            "e38fb1d167a248cfbb6368e92997011c",
            "849e10abe64a46eab7c2d66511e70f2c",
            "e59da3aba7c44e259e0ed1b9f42734a9",
            "dd5d512f287e45d284b60cb879c7379a",
            "879e2d795cab44f99f9ad9c72d94d153",
            "ba5429369269456bafc23d28964685ee",
            "ba8427f07b2f4aa89a8e344e3b891d34",
            "6415ec86d0e44e129a8e077f5bcf18fd",
            "adfd39a27f154a97aad0ccd104835d6d",
            "6ca3b22f9a3e46828dc3e195e1d25a42",
            "cf154e1fe63d425dbc954e6179111893",
            "32affaf3ceb24aeea181b962e08bc6cd",
            "1b6f3e95e6bb4ef7abc894eeeddc299c",
            "5d6c112fad5c41fbbb3b58ee840660d8",
            "350b72ba8ed24f70b65b42fdb67d803a",
            "95f43315cb76414388eefe39faa10c2a",
            "fa07ce966cb347ef8a8392e33c85a470",
            "94a0bf7ab4954c3d81c0241014e53720",
            "1ffa3927a2244eea9b9f79f5047083d6",
            "e6a40ab775994146b8f7095ada3b8d25",
            "4e498e8756f84eb7a8f45b827cf2909a",
            "23bf9393b80a4b218756171f624e3992",
            "ad71954fe361464ca13bce130d1dec99",
            "5c350c30d39d4d34bad0062371fcbd75",
            "155169cba80e4a909288d39b7ab02fb5",
            "8f35cbf1789140079aef3bf9b3368c54",
            "e3e112bc90fb46b38cc43e7ebee259bc",
            "f129ebc087a64613b7b2e87239d36df0",
            "37e98402400248b4bdab02c3a77d218d",
            "2d0e280b520b42a4b00ca07ff4c991c1",
            "1f71550e58494d97813dcd0218c5e940",
            "f3335985fb264ac3961b1f6b01d1fb06",
            "93dee78acd204a7fa5cd7f1799742953",
            "8e42da2434934871bebc46e3d1c9a23e",
            "018b8a71388240ab8fe8ad547f05961a",
            "12c7a185cac04efaad8aceddb0bcd00f",
            "cc6c46715bec457d958f73e5b022152e",
            "8a02a998ce664f50b327cd21db218ae7",
            "c76b656954df49d1b98729837ba8df69",
            "f0353be70e414c0e89958ee576a1e470",
            "251e3cbb7127466c9f9b5f85f83868b6",
            "4d6863d691674c178c806266cdc43963",
            "c7d6f894b9f14068b869a2c6d2804e1d",
            "205cf9eb218a4cfba805864997f802d8",
            "af3d68e5ad26451da4908b0626f0634e",
            "f4faa6c07bba4cea866edf015f8b7d60",
            "78891c08c12648b6b56560afc2083848",
            "0381fcf17f944943bc682088e2cc3415",
            "c82bf322d7574b7c803e767c0ff8bae3",
            "8668fee75c9c4a0b997b2fc662542491",
            "06942a3261124f0eba51228f2284d95a",
            "375eeaefb2204ab091498880244e5339",
            "9e9df74c4db44772b02e990cfdfe01b1",
            "5b84f2bba002448baf2bb63c811e9ad5",
            "76f4268d44ee42bab35c6e042ddae8a7",
            "bab41a5e445f4909983dd8e5b25c9fe1",
            "7240cc9041be466baad6c24e90de7f10",
            "1ed8f5c71e3c45499e6d41f41d90dc12",
            "da246495a87f45468de5bd5571b30a14",
            "8ed231e81e244b81900d503c065ae836",
            "210017003e664591937cb71ebc3fa54c",
            "c07e723b094c46129f66496a99315c64",
            "0d37fa6c76bd46e78739e6780031b213",
            "8e5b4fed93984be7bdb7aa96000fa7fb",
            "d1388a96f8b74d4ab524af0d0fe377c7",
            "681a006142c94e03b4d35677b3b66f78",
            "73e39679513e41898b404afc11f9259c",
            "4dfd2463362441f1b524105d47d12bd6",
            "61682d66225640a791c5ec00b2970867",
            "92a804b17bc74bebba543b4049e56142",
            "2241675bcd734188864780ca8f35e48d",
            "c90f0c7a58f94ffab84145255256720b",
            "b6fbe67213ba466b860e3a659bfe6505",
            "570b90c852ab493b9402597835bf7ce9",
            "7e1b05b3b0f4496696a979f3f7caaf1e",
            "990f2d7b6913499d91e2c997d27fe6e1",
            "e3716ff6439d4c46a65860c447a155d7",
            "bedf1de5f4ad4450b81130de59014462",
            "ef6b1d8c93504b929cb2822f2e4ade6e",
            "867b657f56a14dc1b3ac451f332d3434",
            "3644ab5ec65e4b32a75fb2dabd9086ca",
            "09c2c38823084975bb73f2cb84b6ceb3",
            "b5c0691b411a453ea276d0f63cbe702c",
            "1db59ff5e9c84c68855df6cdbbd9ec02",
            "cfaf24077c48400ab747d047ba511896",
            "ca7c9548a58645e7b704afb9b1f851b5",
            "d9fbd1d7abe74d2baa43fef390a63f6b",
            "5d848f6ca92b42dfbe3f0dac5ab5ca1a",
            "0a9a73eb53cd4854bbdf38e86c8f3ef6",
            "c7f1e4c0af5e40ed93b00e23292d8c17",
            "8adfcaa0ab124783ac5fe54d9141da49",
            "0345127f6f994ee0827024635b89c283",
            "107eb42c42ed464da9bbb76cebf0299a",
            "b53df76e0c344d91911a15a4d00f851c",
            "a4feefb75c1545eea2ad79751228592b",
            "57199fdaa44a4e8fb152b9be98e6fa7e",
            "f8a464a63f0f4c53854f50dd71ed4867",
            "40ee9249cf104fbba4259cc587d09798",
            "6d5945eadd20492b9f31952dd24c6da8",
            "2a39eb04b0bc420b9cce9d348842cfc7",
            "9fb88904db73420b988fbcbaa76c5841",
            "b1af8032c0fa48d391ffaad2ee6cff9a",
            "64add1fc29f04f95811d12e2633a971e",
            "ebcdd896f05f4423b67ce83a01f855df",
            "c83eda79cdd647458bea4d219b2f9936",
            "d78a2049758b4ef4baa533025e71c0e5",
            "07997443d0754de99ac6a65970b9ec89",
            "7750eb565e944468a992882709bf4353",
            "56fa6e6940d74df9b188cd8df4ed0e08",
            "4687dc2c482140cca973bff76160eeb5",
            "f8314f2e31864f23aa11eda011abfdb1",
            "adb7a9b0cb0448c1a2f71898ad38c9a8",
            "9432bcd2b961472cb1587e981c07f6f1",
            "5bb63b711c824f9ab3a5bea1cd9de396",
            "8e0b45610d8c459ea5e32242b4c7b083",
            "c095127dd3634182b19629b0a9c930ad",
            "5215432d14c34974ab393afe3cc56974",
            "24b6c0a4959549eab3185de2af15b061",
            "47b10f6105204a8ba4b76876c8b2758a",
            "c76e584b467b46df97de42b732b04cdb",
            "3336812d244b49c78e3bf60e8cdd491f",
            "422b26a0fac54763b88ddc428b21e062",
            "6ee0d9a1234449f1b0861d64e01c0611",
            "b333eb4023bd4cf2b714ced1bd0ba227",
            "e6560aabc5b545788f468945e7946349",
            "05d7ea54854f42aca07b2df08d828fa9",
            "10c5985311964bc885eb445040c4caac",
            "540ad51671d746d984ad8522d38b3221",
            "c5c3bff9ac524095a469f2797d02a7d9",
            "a8f03461df3c4cf4b9ceb2c6e2857efb",
            "e4afc20c0cda4f35bef211b855567c07",
            "ff33399ec6cb49b99c527363dd2b8188",
            "f724b69036dc46dba2e1a29da6df374e",
            "6b07d3dc9c334e8e8b823cab116c1eaa",
            "60403a0cc4564c3c9add21fe171d4f92",
            "84a1de907db646eca0edc267015732f0",
            "ec07519818274418844c655993bc4b91",
            "2aa6cd3a19724a23b7e5279eea2a4dfd",
            "a5cb58a8310444f18f5b7cdedd800cf5",
            "d8400dd87b6f4c58a7eccdbc7991c91b",
            "efb8e7cc8ada47efb8067094aa962a12",
            "1e4db92803e64a6f932c0f46cd92385f",
            "d74c7420264a4b8da605c468c0b06e64",
            "57e085438ec847f2ae89221608cf0d4f",
            "445a4cffa359475b9dda98077d3b597f",
            "b5fa53bf05994ff2a3d894d5285c98a6",
            "ddbcc1512ffa49a4ba73a10aa25f9dc8",
            "a190b341058f47aa9d93d8a6afac664f",
            "7b882ae448184812a6ef8aab8aa0e50f",
            "badfd2540485431fb0398b7d195ec251",
            "f632c62d944b405589f40e5c27713f22",
            "6896128c5f314dae95374ff5119ff88e",
            "b23d627a85de4c9ca09ce2b0ec6405ec",
            "9df34b1d83384320b8df2664fed12601",
            "d9ae6f966e5849fbbd8fb20dc27c84e8",
            "7e93adcbd4304f3d81f1e60db082ca7d",
            "f839b1707ee84682b70f00ebf202cdd2",
            "1f90bae00700466c893e10ce5ea3773d",
            "b6aa75119cd24010a891623c5575f1fa",
            "d0096689a338470b8876a3c6b0ccd5d5",
            "a448c039b7c646faac7d8481b6fe856d",
            "928ef5f6b979422fba58299f8940a200",
            "914f8d73c8574ead902a233a2869b181",
            "77f3718c9d2c41af90172bee379a700f",
            "35261eb3612d4a8a94470e77e489d174",
            "2adc99b82b8b4b88bd70babf2b3513f4",
            "c2fe819347244fa0ad44bcecc4d3bdfe",
            "03a86bc85ba84e778e2d64b0a553fdda",
            "1bb4f7badf344b09bc01f51ac7bbe14e",
            "4429058a80214d77a8e4abdd03cbc08a",
            "ec6985a1a9ac4a9eb290c1c365b3b790",
            "b8af1793c3fe4a4894d00f04311286f5",
            "129b5a7f1e3f4cd88486ca2d4271f810",
            "ebb9daf3010c49b6bf00a7a9f9c034b3",
            "7784d254310d490785f68d1c0f2d897a",
            "40272faad7834c8cb95ffbaf98e1e589",
            "3124ef25f35640578220efdd84b1d978",
            "a0f58d47f4e44a959b6e086a7edad5ba",
            "cd3573bbf4c74513bed9cf3f50e5072a",
            "7d305df06e4e4e03a6b71796564e58e4",
            "f5044d36ed4a46f1b22ce5232581cb52",
            "87f3ebd1900e41baa4ffb2775374f0ca",
            "f29b4749439d41ed9488326ed5cfca11",
            "e4eb70ca0a7c43759795a5a283df04ad",
            "9f00de29822647e386a78c1ce907024d",
            "1f7002f2b4194189b13bfc7c47cd4d16",
            "b30a8413a2364edfac3c323d0bba643e",
            "fc823cf8a950454cb3e128ad36877bb4",
            "68d941fe71d6424eae43a6aee2d2a5f2",
            "7047a27be47042f7b5083b6b290dc11d",
            "fa9d7d08ac0944cb9c7ec5a2fab4cd12",
            "a6f0de0e218e43a1ac4b90c545999f91",
            "900c04ba2b03483a9e578337f0d71ac0",
            "5d2a14cce54448a3bb8b0f2459a93d28",
            "c9eec94034404ff18043936a6f7756de",
            "435cce18c9b54a96b4f1196517572dd0",
            "9347e8460dfd455bb41dfd7fbef5db9f",
            "b7daf82b0831432b955d2e3d12517012",
            "437c130a16ae4d7c984856e31ac5134c",
            "26afedf9a27d45f588d4fbd16e3dbe6d",
            "de7c70c724ad4cb2ab1097f5cd53901b",
            "a9b4daf88a7f4454a1cc1bf719c34b4b"
          ]
        },
        "id": "f340e951-5018-4359-98b4-5a8676c14fdf",
        "outputId": "c0bd0a88-397f-4be1-84ed-54c429695591"
      },
      "source": [
        "print(\"Starting the complete processing pipeline\")\n",
        "df_final = run_processing_pipeline()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the complete processing pipeline\n",
            "============================================================\n",
            "Starting optimized batch processing pipeline\n",
            "============================================================\n",
            "Found 11116 multi-ad files\n",
            "Found 2907 single-ad files\n",
            "Total files to process: 14023\n",
            "Progress loaded: 2250 files already completed\n",
            "Remaining files to process: 11773\n",
            "Will process in 471 batches of 25 files each\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 1/471\n",
            "Files 1-25 of 11773\n",
            "Memory at start: GPU: 0.00GB allocated, 0.00GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.00GB allocated, 0.00GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc525328bc454f88b323c440029de845",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c00fae74a3784d6ca98794697edc9120",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffa03d32760748a1b9a60fa5f826bcb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5329467d74fd4071a24b064492d17365",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94cecb7a9f5044ce98dacd85a1507fa8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/504M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27db0446f4dd475d8e619d62d8c94582",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/504M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory after BERT: GPU: 0.00GB allocated, 0.00GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b6958ae13884be2afe026ceef3cfc79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f060f691b4854ce59d9be912f373e55f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c05b62f0bba34f35bfbbaedbe2c1618a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96260f9cd42a4aef92915f8006623098",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eef87e9e3483470f861fadd8fc4b4a40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28adc8e2ad37404aa579aecc8a1b56d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "690d945a7e7948e5ae63684a15d0c107",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4f001318f0b48d9bf03e8f2f55ce10d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2c0a1da161b491a82401f3de01786ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/290 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b9ae152c60b4a31aa4f0032c453755f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "879e2d795cab44f99f9ad9c72d94d153",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95f43315cb76414388eefe39faa10c2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3e112bc90fb46b38cc43e7ebee259bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a02a998ce664f50b327cd21db218ae7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c82bf322d7574b7c803e767c0ff8bae3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ed231e81e244b81900d503c065ae836",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2241675bcd734188864780ca8f35e48d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09c2c38823084975bb73f2cb84b6ceb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "107eb42c42ed464da9bbb76cebf0299a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebcdd896f05f4423b67ce83a01f855df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e0b45610d8c459ea5e32242b4c7b083",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05d7ea54854f42aca07b2df08d828fa9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/470M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec07519818274418844c655993bc4b91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a190b341058f47aa9d93d8a6afac664f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/470M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6aa75119cd24010a891623c5575f1fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4429058a80214d77a8e4abdd03cbc08a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5044d36ed4a46f1b22ce5232581cb52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6f0de0e218e43a1ac4b90c545999f91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/251 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 1 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_001.csv\n",
            "Batch 1 successfully saved\n",
            "Progress saved: Batch 1/471, 2275 files completed\n",
            "Batch 1 complete. Total completed: 2275\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 2/471\n",
            "Files 26-50 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Basic processing:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "Basic processing:   4%|▍         | 1/25 [00:04<01:45,  4.40s/it]\u001b[A\n",
            "Basic processing:   8%|▊         | 2/25 [00:09<01:44,  4.52s/it]\u001b[A\n",
            "Basic processing:  12%|█▏        | 3/25 [00:13<01:40,  4.58s/it]\u001b[A\n",
            "Basic processing:  16%|█▌        | 4/25 [00:19<01:45,  5.01s/it]\u001b[A\n",
            "Basic processing:  20%|██        | 5/25 [00:20<01:09,  3.49s/it]\u001b[A\n",
            "Basic processing:  24%|██▍       | 6/25 [00:21<00:50,  2.66s/it]\u001b[A\n",
            "Basic processing:  28%|██▊       | 7/25 [00:21<00:36,  2.05s/it]\u001b[A\n",
            "Basic processing:  32%|███▏      | 8/25 [00:22<00:27,  1.63s/it]\u001b[A\n",
            "Basic processing:  36%|███▌      | 9/25 [00:24<00:27,  1.69s/it]\u001b[A\n",
            "Basic processing:  40%|████      | 10/25 [00:28<00:34,  2.27s/it]\u001b[A\n",
            "Basic processing:  44%|████▍     | 11/25 [00:35<00:52,  3.75s/it]\u001b[A\n",
            "Basic processing:  48%|████▊     | 12/25 [00:38<00:46,  3.56s/it]\u001b[A\n",
            "Basic processing:  52%|█████▏    | 13/25 [00:45<00:55,  4.66s/it]\u001b[A\n",
            "Basic processing:  56%|█████▌    | 14/25 [00:47<00:40,  3.71s/it]\u001b[A\n",
            "Basic processing:  60%|██████    | 15/25 [00:51<00:39,  3.97s/it]\u001b[A\n",
            "Basic processing:  64%|██████▍   | 16/25 [00:54<00:32,  3.62s/it]\u001b[A\n",
            "Basic processing:  68%|██████▊   | 17/25 [00:55<00:22,  2.78s/it]\u001b[A\n",
            "Basic processing:  72%|███████▏  | 18/25 [00:58<00:21,  3.05s/it]\u001b[A\n",
            "Basic processing:  76%|███████▌  | 19/25 [00:59<00:14,  2.35s/it]\u001b[A\n",
            "Basic processing:  80%|████████  | 20/25 [01:01<00:11,  2.34s/it]\u001b[A\n",
            "Basic processing:  84%|████████▍ | 21/25 [01:04<00:09,  2.38s/it]\u001b[A\n",
            "Basic processing:  88%|████████▊ | 22/25 [01:13<00:12,  4.27s/it]\u001b[A\n",
            "Basic processing:  92%|█████████▏| 23/25 [01:17<00:08,  4.24s/it]\u001b[A\n",
            "Basic processing:  96%|█████████▌| 24/25 [01:18<00:03,  3.37s/it]\u001b[A\n",
            "Basic processing: 100%|██████████| 25/25 [01:21<00:00,  3.24s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 2 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_002.csv\n",
            "Batch 2 successfully saved\n",
            "Progress saved: Batch 2/471, 2300 files completed\n",
            "Batch 2 complete. Total completed: 2300\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 3/471\n",
            "Files 51-75 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:06<00:00,  2.66s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 3 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_003.csv\n",
            "Batch 3 successfully saved\n",
            "Progress saved: Batch 3/471, 2325 files completed\n",
            "Batch 3 complete. Total completed: 2325\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 4/471\n",
            "Files 76-100 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:40<00:00,  1.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 4 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_004.csv\n",
            "Batch 4 successfully saved\n",
            "Progress saved: Batch 4/471, 2350 files completed\n",
            "Batch 4 complete. Total completed: 2350\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 5/471\n",
            "Files 101-125 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.91GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 5 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_005.csv\n",
            "Batch 5 successfully saved\n",
            "Progress saved: Batch 5/471, 2375 files completed\n",
            "Batch 5 complete. Total completed: 2375\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 6/471\n",
            "Files 126-150 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:41<00:00,  1.67s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 6 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_006.csv\n",
            "Batch 6 successfully saved\n",
            "Progress saved: Batch 6/471, 2400 files completed\n",
            "Batch 6 complete. Total completed: 2400\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 7/471\n",
            "Files 151-175 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:54<00:00,  2.16s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 7 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_007.csv\n",
            "Batch 7 successfully saved\n",
            "Progress saved: Batch 7/471, 2425 files completed\n",
            "Batch 7 complete. Total completed: 2425\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 8/471\n",
            "Files 176-200 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 8 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_008.csv\n",
            "Batch 8 successfully saved\n",
            "Progress saved: Batch 8/471, 2450 files completed\n",
            "Batch 8 complete. Total completed: 2450\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 9/471\n",
            "Files 201-225 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 9 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_009.csv\n",
            "Batch 9 successfully saved\n",
            "Progress saved: Batch 9/471, 2475 files completed\n",
            "Batch 9 complete. Total completed: 2475\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 10/471\n",
            "Files 226-250 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 10 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_010.csv\n",
            "Batch 10 successfully saved\n",
            "Progress saved: Batch 10/471, 2500 files completed\n",
            "Batch 10 complete. Total completed: 2500\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 11/471\n",
            "Files 251-275 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:51<00:00,  2.06s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 11 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_011.csv\n",
            "Batch 11 successfully saved\n",
            "Progress saved: Batch 11/471, 2525 files completed\n",
            "Batch 11 complete. Total completed: 2525\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 12/471\n",
            "Files 276-300 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 12 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_012.csv\n",
            "Batch 12 successfully saved\n",
            "Progress saved: Batch 12/471, 2550 files completed\n",
            "Batch 12 complete. Total completed: 2550\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 13/471\n",
            "Files 301-325 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:54<00:00,  2.19s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 13 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_013.csv\n",
            "Batch 13 successfully saved\n",
            "Progress saved: Batch 13/471, 2575 files completed\n",
            "Batch 13 complete. Total completed: 2575\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 14/471\n",
            "Files 326-350 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 14 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_014.csv\n",
            "Batch 14 successfully saved\n",
            "Progress saved: Batch 14/471, 2600 files completed\n",
            "Batch 14 complete. Total completed: 2600\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 15/471\n",
            "Files 351-375 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:51<00:00,  2.06s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 15 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_015.csv\n",
            "Batch 15 successfully saved\n",
            "Progress saved: Batch 15/471, 2625 files completed\n",
            "Batch 15 complete. Total completed: 2625\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 16/471\n",
            "Files 376-400 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:09<00:00,  2.78s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 16 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_016.csv\n",
            "Batch 16 successfully saved\n",
            "Progress saved: Batch 16/471, 2650 files completed\n",
            "Batch 16 complete. Total completed: 2650\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 17/471\n",
            "Files 401-425 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:58<00:00,  2.32s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 17 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_017.csv\n",
            "Batch 17 successfully saved\n",
            "Progress saved: Batch 17/471, 2675 files completed\n",
            "Batch 17 complete. Total completed: 2675\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 18/471\n",
            "Files 426-450 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:57<00:00,  2.30s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 18 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_018.csv\n",
            "Batch 18 successfully saved\n",
            "Progress saved: Batch 18/471, 2700 files completed\n",
            "Batch 18 complete. Total completed: 2700\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 19/471\n",
            "Files 451-475 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:36<00:00,  1.47s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 19 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_019.csv\n",
            "Batch 19 successfully saved\n",
            "Progress saved: Batch 19/471, 2725 files completed\n",
            "Batch 19 complete. Total completed: 2725\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 20/471\n",
            "Files 476-500 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:39<00:00,  1.58s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 20 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_020.csv\n",
            "Batch 20 successfully saved\n",
            "Progress saved: Batch 20/471, 2750 files completed\n",
            "Batch 20 complete. Total completed: 2750\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 21/471\n",
            "Files 501-525 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:55<00:00,  2.23s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 21 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_021.csv\n",
            "Batch 21 successfully saved\n",
            "Progress saved: Batch 21/471, 2775 files completed\n",
            "Batch 21 complete. Total completed: 2775\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 22/471\n",
            "Files 526-550 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:53<00:00,  2.15s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 22 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_022.csv\n",
            "Batch 22 successfully saved\n",
            "Progress saved: Batch 22/471, 2800 files completed\n",
            "Batch 22 complete. Total completed: 2800\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 23/471\n",
            "Files 551-575 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:03<00:00,  2.52s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 23 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_023.csv\n",
            "Batch 23 successfully saved\n",
            "Progress saved: Batch 23/471, 2825 files completed\n",
            "Batch 23 complete. Total completed: 2825\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 24/471\n",
            "Files 576-600 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:53<00:00,  2.13s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 24 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_024.csv\n",
            "Batch 24 successfully saved\n",
            "Progress saved: Batch 24/471, 2850 files completed\n",
            "Batch 24 complete. Total completed: 2850\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 25/471\n",
            "Files 601-625 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:52<00:00,  2.09s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 25 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_025.csv\n",
            "Batch 25 successfully saved\n",
            "Progress saved: Batch 25/471, 2875 files completed\n",
            "Batch 25 complete. Total completed: 2875\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 26/471\n",
            "Files 626-650 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 26 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_026.csv\n",
            "Batch 26 successfully saved\n",
            "Progress saved: Batch 26/471, 2900 files completed\n",
            "Batch 26 complete. Total completed: 2900\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 27/471\n",
            "Files 651-675 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:47<00:00,  1.89s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 27 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_027.csv\n",
            "Batch 27 successfully saved\n",
            "Progress saved: Batch 27/471, 2925 files completed\n",
            "Batch 27 complete. Total completed: 2925\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 28/471\n",
            "Files 676-700 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:55<00:00,  2.24s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 28 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_028.csv\n",
            "Batch 28 successfully saved\n",
            "Progress saved: Batch 28/471, 2950 files completed\n",
            "Batch 28 complete. Total completed: 2950\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 29/471\n",
            "Files 701-725 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:49<00:00,  1.97s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 29 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_029.csv\n",
            "Batch 29 successfully saved\n",
            "Progress saved: Batch 29/471, 2975 files completed\n",
            "Batch 29 complete. Total completed: 2975\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 30/471\n",
            "Files 726-750 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:53<00:00,  2.12s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 30 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_030.csv\n",
            "Batch 30 successfully saved\n",
            "Progress saved: Batch 30/471, 3000 files completed\n",
            "Batch 30 complete. Total completed: 3000\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 31/471\n",
            "Files 751-775 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:19<00:00,  3.19s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 31 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_031.csv\n",
            "Batch 31 successfully saved\n",
            "Progress saved: Batch 31/471, 3025 files completed\n",
            "Batch 31 complete. Total completed: 3025\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 32/471\n",
            "Files 776-800 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:55<00:00,  2.22s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 32 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_032.csv\n",
            "Batch 32 successfully saved\n",
            "Progress saved: Batch 32/471, 3050 files completed\n",
            "Batch 32 complete. Total completed: 3050\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 33/471\n",
            "Files 801-825 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.47GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.91GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 33 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_033.csv\n",
            "Batch 33 successfully saved\n",
            "Progress saved: Batch 33/471, 3075 files completed\n",
            "Batch 33 complete. Total completed: 3075\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 34/471\n",
            "Files 826-850 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 34 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_034.csv\n",
            "Batch 34 successfully saved\n",
            "Progress saved: Batch 34/471, 3100 files completed\n",
            "Batch 34 complete. Total completed: 3100\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 35/471\n",
            "Files 851-875 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:43<00:00,  1.75s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 35 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_035.csv\n",
            "Batch 35 successfully saved\n",
            "Progress saved: Batch 35/471, 3125 files completed\n",
            "Batch 35 complete. Total completed: 3125\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 36/471\n",
            "Files 876-900 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:14<00:00,  2.97s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.47GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.91GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 36 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_036.csv\n",
            "Batch 36 successfully saved\n",
            "Progress saved: Batch 36/471, 3150 files completed\n",
            "Batch 36 complete. Total completed: 3150\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 37/471\n",
            "Files 901-925 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 37 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_037.csv\n",
            "Batch 37 successfully saved\n",
            "Progress saved: Batch 37/471, 3175 files completed\n",
            "Batch 37 complete. Total completed: 3175\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 38/471\n",
            "Files 926-950 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:52<00:00,  2.12s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 38 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_038.csv\n",
            "Batch 38 successfully saved\n",
            "Progress saved: Batch 38/471, 3200 files completed\n",
            "Batch 38 complete. Total completed: 3200\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 39/471\n",
            "Files 951-975 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.91GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 39 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_039.csv\n",
            "Batch 39 successfully saved\n",
            "Progress saved: Batch 39/471, 3225 files completed\n",
            "Batch 39 complete. Total completed: 3225\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 40/471\n",
            "Files 976-1000 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 40 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_040.csv\n",
            "Batch 40 successfully saved\n",
            "Progress saved: Batch 40/471, 3250 files completed\n",
            "Batch 40 complete. Total completed: 3250\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 41/471\n",
            "Files 1001-1025 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:07<00:00,  2.68s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 41 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_041.csv\n",
            "Batch 41 successfully saved\n",
            "Progress saved: Batch 41/471, 3275 files completed\n",
            "Batch 41 complete. Total completed: 3275\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 42/471\n",
            "Files 1026-1050 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:54<00:00,  2.16s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 42 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_042.csv\n",
            "Batch 42 successfully saved\n",
            "Progress saved: Batch 42/471, 3300 files completed\n",
            "Batch 42 complete. Total completed: 3300\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 43/471\n",
            "Files 1051-1075 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:55<00:00,  2.21s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 43 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_043.csv\n",
            "Batch 43 successfully saved\n",
            "Progress saved: Batch 43/471, 3325 files completed\n",
            "Batch 43 complete. Total completed: 3325\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 44/471\n",
            "Files 1076-1100 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:44<00:00,  1.78s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 44 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_044.csv\n",
            "Batch 44 successfully saved\n",
            "Progress saved: Batch 44/471, 3350 files completed\n",
            "Batch 44 complete. Total completed: 3350\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 45/471\n",
            "Files 1101-1125 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:54<00:00,  2.20s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 45 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_045.csv\n",
            "Batch 45 successfully saved\n",
            "Progress saved: Batch 45/471, 3375 files completed\n",
            "Batch 45 complete. Total completed: 3375\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 46/471\n",
            "Files 1126-1150 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:50<00:00,  2.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 46 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_046.csv\n",
            "Batch 46 successfully saved\n",
            "Progress saved: Batch 46/471, 3400 files completed\n",
            "Batch 46 complete. Total completed: 3400\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 47/471\n",
            "Files 1151-1175 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:44<00:00,  1.78s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 47 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_047.csv\n",
            "Batch 47 successfully saved\n",
            "Progress saved: Batch 47/471, 3425 files completed\n",
            "Batch 47 complete. Total completed: 3425\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 48/471\n",
            "Files 1176-1200 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:44<00:00,  1.77s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 48 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_048.csv\n",
            "Batch 48 successfully saved\n",
            "Progress saved: Batch 48/471, 3450 files completed\n",
            "Batch 48 complete. Total completed: 3450\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 49/471\n",
            "Files 1201-1225 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:16<00:00,  3.07s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 49 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_049.csv\n",
            "Batch 49 successfully saved\n",
            "Progress saved: Batch 49/471, 3475 files completed\n",
            "Batch 49 complete. Total completed: 3475\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 50/471\n",
            "Files 1226-1250 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.91GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 50 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_050.csv\n",
            "Batch 50 successfully saved\n",
            "Progress saved: Batch 50/471, 3500 files completed\n",
            "Batch 50 complete. Total completed: 3500\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 51/471\n",
            "Files 1251-1275 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:50<00:00,  2.00s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 51 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_051.csv\n",
            "Batch 51 successfully saved\n",
            "Progress saved: Batch 51/471, 3525 files completed\n",
            "Batch 51 complete. Total completed: 3525\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 52/471\n",
            "Files 1276-1300 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:42<00:00,  1.70s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 52 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_052.csv\n",
            "Batch 52 successfully saved\n",
            "Progress saved: Batch 52/471, 3550 files completed\n",
            "Batch 52 complete. Total completed: 3550\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 53/471\n",
            "Files 1301-1325 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:15<00:00,  3.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.47GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.91GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 53 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_053.csv\n",
            "Batch 53 successfully saved\n",
            "Progress saved: Batch 53/471, 3575 files completed\n",
            "Batch 53 complete. Total completed: 3575\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 54/471\n",
            "Files 1326-1350 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:49<00:00,  1.97s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 54 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_054.csv\n",
            "Batch 54 successfully saved\n",
            "Progress saved: Batch 54/471, 3600 files completed\n",
            "Batch 54 complete. Total completed: 3600\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 55/471\n",
            "Files 1351-1375 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 55 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_055.csv\n",
            "Batch 55 successfully saved\n",
            "Progress saved: Batch 55/471, 3625 files completed\n",
            "Batch 55 complete. Total completed: 3625\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 56/471\n",
            "Files 1376-1400 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:08<00:00,  2.74s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 56 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_056.csv\n",
            "Batch 56 successfully saved\n",
            "Progress saved: Batch 56/471, 3650 files completed\n",
            "Batch 56 complete. Total completed: 3650\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 57/471\n",
            "Files 1401-1425 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 57 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_057.csv\n",
            "Batch 57 successfully saved\n",
            "Progress saved: Batch 57/471, 3675 files completed\n",
            "Batch 57 complete. Total completed: 3675\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 58/471\n",
            "Files 1426-1450 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 58 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_058.csv\n",
            "Batch 58 successfully saved\n",
            "Progress saved: Batch 58/471, 3700 files completed\n",
            "Batch 58 complete. Total completed: 3700\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 59/471\n",
            "Files 1451-1475 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:54<00:00,  2.17s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 59 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_059.csv\n",
            "Batch 59 successfully saved\n",
            "Progress saved: Batch 59/471, 3725 files completed\n",
            "Batch 59 complete. Total completed: 3725\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 60/471\n",
            "Files 1476-1500 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:54<00:00,  2.18s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 60 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_060.csv\n",
            "Batch 60 successfully saved\n",
            "Progress saved: Batch 60/471, 3750 files completed\n",
            "Batch 60 complete. Total completed: 3750\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 61/471\n",
            "Files 1501-1525 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:51<00:00,  2.06s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 61 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_061.csv\n",
            "Batch 61 successfully saved\n",
            "Progress saved: Batch 61/471, 3775 files completed\n",
            "Batch 61 complete. Total completed: 3775\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 62/471\n",
            "Files 1526-1550 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:54<00:00,  2.16s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 62 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_062.csv\n",
            "Batch 62 successfully saved\n",
            "Progress saved: Batch 62/471, 3800 files completed\n",
            "Batch 62 complete. Total completed: 3800\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 63/471\n",
            "Files 1551-1575 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:52<00:00,  2.12s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 63 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_063.csv\n",
            "Batch 63 successfully saved\n",
            "Progress saved: Batch 63/471, 3825 files completed\n",
            "Batch 63 complete. Total completed: 3825\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 64/471\n",
            "Files 1576-1600 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:53<00:00,  2.12s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 64 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_064.csv\n",
            "Batch 64 successfully saved\n",
            "Progress saved: Batch 64/471, 3850 files completed\n",
            "Batch 64 complete. Total completed: 3850\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 65/471\n",
            "Files 1601-1625 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:07<00:00,  2.68s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 65 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_065.csv\n",
            "Batch 65 successfully saved\n",
            "Progress saved: Batch 65/471, 3875 files completed\n",
            "Batch 65 complete. Total completed: 3875\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 66/471\n",
            "Files 1626-1650 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 66 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_066.csv\n",
            "Batch 66 successfully saved\n",
            "Progress saved: Batch 66/471, 3900 files completed\n",
            "Batch 66 complete. Total completed: 3900\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 67/471\n",
            "Files 1651-1675 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 67 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_067.csv\n",
            "Batch 67 successfully saved\n",
            "Progress saved: Batch 67/471, 3925 files completed\n",
            "Batch 67 complete. Total completed: 3925\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 68/471\n",
            "Files 1676-1700 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 68 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_068.csv\n",
            "Batch 68 successfully saved\n",
            "Progress saved: Batch 68/471, 3950 files completed\n",
            "Batch 68 complete. Total completed: 3950\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 69/471\n",
            "Files 1701-1725 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:39<00:00,  1.60s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 69 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_069.csv\n",
            "Batch 69 successfully saved\n",
            "Progress saved: Batch 69/471, 3975 files completed\n",
            "Batch 69 complete. Total completed: 3975\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 70/471\n",
            "Files 1726-1750 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:49<00:00,  1.97s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 70 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_070.csv\n",
            "Batch 70 successfully saved\n",
            "Progress saved: Batch 70/471, 4000 files completed\n",
            "Batch 70 complete. Total completed: 4000\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 71/471\n",
            "Files 1751-1775 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:53<00:00,  2.15s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 71 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_071.csv\n",
            "Batch 71 successfully saved\n",
            "Progress saved: Batch 71/471, 4025 files completed\n",
            "Batch 71 complete. Total completed: 4025\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 72/471\n",
            "Files 1776-1800 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 72 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_072.csv\n",
            "Batch 72 successfully saved\n",
            "Progress saved: Batch 72/471, 4050 files completed\n",
            "Batch 72 complete. Total completed: 4050\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 73/471\n",
            "Files 1801-1825 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:45<00:00,  1.83s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 73 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_073.csv\n",
            "Batch 73 successfully saved\n",
            "Progress saved: Batch 73/471, 4075 files completed\n",
            "Batch 73 complete. Total completed: 4075\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 74/471\n",
            "Files 1826-1850 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:57<00:00,  2.29s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 74 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_074.csv\n",
            "Batch 74 successfully saved\n",
            "Progress saved: Batch 74/471, 4100 files completed\n",
            "Batch 74 complete. Total completed: 4100\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 75/471\n",
            "Files 1851-1875 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 75 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_075.csv\n",
            "Batch 75 successfully saved\n",
            "Progress saved: Batch 75/471, 4125 files completed\n",
            "Batch 75 complete. Total completed: 4125\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 76/471\n",
            "Files 1876-1900 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 76 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_076.csv\n",
            "Batch 76 successfully saved\n",
            "Progress saved: Batch 76/471, 4150 files completed\n",
            "Batch 76 complete. Total completed: 4150\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 77/471\n",
            "Files 1901-1925 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Basic processing: 100%|██████████| 25/25 [01:06<00:00,  2.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic features extracted for 25 files\n",
            "Processing batch of 25 images\n",
            "Memory before processing: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Phase 1: BERT Embeddings\n",
            "Loading hebrew_bert...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hebrew BERT loaded\n",
            "Memory after BERT: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "Cleaning up hebrew_bert...\n",
            "hebrew_bert cleaned up\n",
            "Phase 2: Sentiment Analysis\n",
            "Loading hebrew_sentiment...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hebrew sentiment loaded\n",
            "Memory after Sentiment: GPU: 0.42GB allocated, 0.46GB reserved\n",
            "Cleaning up hebrew_sentiment...\n",
            "hebrew_sentiment cleaned up\n",
            "Phase 3: Named Entity Recognition\n",
            "Loading hebrew_ner...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hebrew NER loaded\n",
            "Memory after NER: GPU: 0.82GB allocated, 0.91GB reserved\n",
            "Cleaning up hebrew_ner...\n",
            "hebrew_ner cleaned up\n",
            "Phase 4: Object Detection\n",
            "Loading object_detection...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object detection loaded\n",
            "Memory after Object Detection: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up object_detection...\n",
            "object_detection cleaned up\n",
            "Phase 5: Image Captioning\n",
            "Loading image_captioning...\n",
            "Image captioning loaded\n",
            "Memory after Image Captioning: GPU: 0.82GB allocated, 0.90GB reserved\n",
            "Cleaning up image_captioning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dandelin/vilt-b32-finetuned-vqa and revision d0a1f6a (https://huggingface.co/dandelin/vilt-b32-finetuned-vqa).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_captioning cleaned up\n",
            "Phase 6: Visual Question Answering\n",
            "Loading vqa...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VQA loaded\n",
            "Memory after VQA: GPU: 1.26GB allocated, 1.39GB reserved\n",
            "Cleaning up vqa...\n",
            "vqa cleaned up\n",
            "Batch processing complete. Final memory: GPU: 1.26GB allocated, 1.38GB reserved\n",
            "Batch 77 saved to: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/batch_results/batch_077.csv\n",
            "Batch 77 successfully saved\n",
            "Progress saved: Batch 77/471, 4175 files completed\n",
            "Batch 77 complete. Total completed: 4175\n",
            "Memory after cleanup: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "\n",
            "========================================\n",
            "PROCESSING BATCH 78/471\n",
            "Files 1926-1950 of 11773\n",
            "Memory at start: GPU: 0.01GB allocated, 0.02GB reserved\n",
            "========================================\n",
            "Phase 1: Basic feature extraction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Basic processing:   8%|▊         | 2/25 [00:02<00:27,  1.18s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not df_final.empty:\n",
        "    print(f\"\\nSaving final dataset\")\n",
        "    try:\n",
        "        df_final.to_csv(OUTPUT_CSV, index=False)\n",
        "\n",
        "        # Verify save\n",
        "        file_size = os.path.getsize(OUTPUT_CSV) / 1024**2\n",
        "        print(f\"SUCCESS! Dataset saved:\")\n",
        "        print(f\"  File: {OUTPUT_CSV}\")\n",
        "        print(f\"  Size: {file_size:.2f} MB\")\n",
        "        print(f\"  Records: {len(df_final)}\")\n",
        "        print(f\"  Columns: {len(df_final.columns)}\")\n",
        "\n",
        "        # Quick data check\n",
        "        print(f\"\\nQuick data check:\")\n",
        "        print(f\"  Ad types: {df_final['ad_type'].value_counts().to_dict()}\")\n",
        "        print(f\"  Files with Hebrew text: {(df_final['text_heb_length'] > 0).sum()}\")\n",
        "        print(f\"  Files with prices: {(df_final['price_count'] > 0).sum()}\")\n",
        "\n",
        "        print(f\"\\nYour dataset is ready for analysis!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving final dataset: {e}\")\n",
        "else:\n",
        "    print(\"No data to save!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u70AOJtyt2BZ",
        "outputId": "216936ab-3584-4932-ea6a-636368091fc8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving final dataset\n",
            "SUCCESS! Dataset saved:\n",
            "  File: /content/drive/MyDrive/Miki_class/Project/Catalog/processed_ads/ads_features.csv\n",
            "  Size: 42.39 MB\n",
            "  Records: 2725\n",
            "  Columns: 48\n",
            "\n",
            "Quick data check:\n",
            "  Ad types: {'multi': 1925, 'single': 800}\n",
            "  Files with Hebrew text: 2442\n",
            "  Files with prices: 0\n",
            "\n",
            "Your dataset is ready for analysis!\n"
          ]
        }
      ]
    }
  ]
}